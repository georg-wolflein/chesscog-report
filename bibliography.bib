
@online{64squares2020,
  title = {Magnus {{Carlsen Chess Games}}},
  author = {{64 Squares}},
  date = {2020-02},
  journaltitle = {PGN Mentor},
  url = {https://www.pgnmentor.com/players/Carlsen/}
}
% == BibLateX quality report for 64squares2020:
% Unexpected field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@online{acher2016,
  title = {Large-Scale {{Analysis}} of {{Chess Games}} with {{Chess Engines}}: {{A Preliminary Report}}},
  shorttitle = {Large-Scale {{Analysis}} of {{Chess Games}} with {{Chess Engines}}},
  author = {Acher, Mathieu and Esnault, François},
  date = {2016-04-28},
  abstract = {The strength of chess engines together with the availability of numerous chess games have attracted the attention of chess players, data scientists, and researchers during the last decades. State-of-the-art engines now provide an authoritative judgement that can be used in many applications like cheating detection, intrinsic ratings computation, skill assessment, or the study of human decision-making. A key issue for the research community is to gather a large dataset of chess games together with the judgement of chess engines. Unfortunately the analysis of each move takes lots of times. In this paper, we report our effort to analyse almost 5 millions chess games with a computing grid. During summer 2015, we processed 270 millions unique played positions using the Stockfish engine with a quite high depth (20). We populated a database of 1+ tera-octets of chess evaluations, representing an estimated time of 50 years of computation on a single machine. Our effort is a first step towards the replication of research results, the supply of open data and procedures for exploring new directions, and the investigation of software engineering/scalability issues when computing billions of moves.},
  archivePrefix = {arXiv},
  eprint = {1607.04186},
  eprinttype = {arxiv},
  file = {/Users/georg/Zotero/storage/VK282A6H/Acher and Esnault - 2016 - Large-scale Analysis of Chess Games with Chess Eng.pdf;/Users/georg/Zotero/storage/EA895GBW/1607.html},
  keywords = {Computer Science - Artificial Intelligence}
}
% == BibLateX quality report for acher2016:
% Unexpected field 'archivePrefix'

@article{baird1990,
  title = {Reading Chess},
  author = {Baird, H.S. and Thompson, K.},
  date = {1990-06},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {12},
  pages = {552--559},
  abstract = {By applying semantic analysis to images of extended passages of text, several volumes of a chess encyclopedia have been read with high accuracy. Although carefully proofread, the books were poorly printed and posed a severe challenge to conventional page-layout analysis and character-recognition methods. An experimental page-reader system performed strictly top-down layout analysis for identification of columns, lines, words, and characters. This proceeded rapidly and reliably thanks to a recently developed skew-estimation technique. Resegmentation of broken, touching, and dirty characters was handled in an efficient and integrated manner by a heuristic search operating on isolated words. By analyzing the syntax of game descriptions and applying the rules of chess, the error rate was reduced by a factor of 30 from what was achievable through shape analysis alone. Several computer vision systems integration issues suggested by this experience are discussed.{$<>$}},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  file = {/Users/georg/Zotero/storage/WARIFC45/Baird and Thompson - 1990 - Reading chess.pdf;/Users/georg/Zotero/storage/3JNWKN5V/56191.html},
  keywords = {Books,character recognition,character-recognition,chess reading,computer vision,Computer vision,Encyclopedias,Error analysis,heuristic search,Image analysis,page-reader system,Performance analysis,semantic analysis,Shape,skew-estimation},
  number = {6}
}
% == BibLateX quality report for baird1990:
% Unexpected field 'eventtitle'

@inproceedings{banerjee2012,
  title = {A {{Simple Autonomous Chess Playing Robot}} for Playing {{Chess}} against Any Opponent in {{Real Time}}},
  booktitle = {International {{Conference}} on {{Computational Vision}} and {{Robotics}}},
  author = {Banerjee, Nandan and Saha, Debal and Singh, Atikant and Sanyal, Gautam},
  date = {2012-08},
  volume = {58},
  pages = {17--22},
  publisher = {{Interscience Research Network}},
  location = {{Bhubaneshwar, India}},
  eventtitle = {International {{Conference}} on {{Computational Vision}} and {{Robotics}}},
  file = {/Users/georg/Zotero/storage/GVGX8VH9/GVGX8VH9.pdf}
}
% == BibLateX quality report for banerjee2012:
% ? Unsure about the formatting of the booktitle

@article{bennett2014,
  title = {{{ChESS}} – {{Quick}} and Robust Detection of Chess-Board Features},
  author = {Bennett, Stuart and Lasenby, Joan},
  date = {2014-01-01},
  journaltitle = {Computer Vision and Image Understanding},
  shortjournal = {Computer Vision and Image Understanding},
  volume = {118},
  pages = {197--210},
  abstract = {Localization of chess-board vertices is a common task in computer vision, underpinning many applications, but relatively little work focusses on designing a specific feature detector that is fast, accurate and robust. In this paper the ‘Chess-board Extraction by Subtraction and Summation’ (ChESS) feature detector, designed to exclusively respond to chess-board vertices, is presented. The method proposed is robust against noise, poor lighting and poor contrast, requires no prior knowledge of the extent of the chess-board pattern, is computationally very efficient, and provides a strength measure of detected features. Such a detector has significant application both in the key field of camera calibration, as well as in structured light 3D reconstruction. Evidence is presented showing its superior robustness, accuracy, and efficiency in comparison to other commonly used detectors, including Harris \& Stephens and SUSAN, both under simulation and in experimental 3D reconstruction of flat plate and cylindrical objects.},
  file = {/Users/georg/Zotero/storage/4T6K8GSE/4T6K8GSE.pdf;/Users/georg/Zotero/storage/IESL7ENN/S1077314213001999.html},
  keywords = {Camera calibration,Chess-board corner detection,Feature extraction,Pattern recognition,Photogrammetric marker detection,Structured light surface measurement},
  langid = {english}
}

@article{bilalic2010,
  title = {Mechanisms and Neural Basis of Object and Pattern Recognition: {{A}} Study with Chess Experts},
  shorttitle = {Mechanisms and Neural Basis of Object and Pattern Recognition},
  author = {Bilalić, Merim and Langner, Robert and Erb, Michael and Grodd, Wolfgang},
  date = {2010},
  journaltitle = {Journal of Experimental Psychology},
  volume = {139},
  pages = {728--742},
  publisher = {{American Psychological Association}},
  location = {{US}},
  abstract = {Comparing experts with novices offers unique insights into the functioning of cognition, based on the maximization of individual differences. Here we used this expertise approach to disentangle the mechanisms and neural basis behind two processes that contribute to everyday expertise: object and pattern recognition. We compared chess experts and novices performing chess-related and -unrelated (visual) search tasks. As expected, the superiority of experts was limited to the chess-specific task, as there were no differences in a control task that used the same chess stimuli but did not require chess-specific recognition. The analysis of eye movements showed that experts immediately and exclusively focused on the relevant aspects in the chess task, whereas novices also examined irrelevant aspects. With random chess positions, when pattern knowledge could not be used to guide perception, experts nevertheless maintained an advantage. Experts' superior domain-specific parafoveal vision, a consequence of their knowledge about individual domain-specific symbols, enabled improved object recognition. Functional magnetic resonance imaging corroborated this differentiation between object and pattern recognition and showed that chess-specific object recognition was accompanied by bilateral activation of the occipitotemporal junction, whereas chess-specific pattern recognition was related to bilateral activations in the middle part of the collateral sulci. Using the expertise approach together with carefully chosen controls and multiple dependent measures, we identified object and pattern recognition as two essential cognitive processes in expert visual cognition, which may also help to explain the mechanisms of everyday perception. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/georg/Zotero/storage/Q8TE2ARY/Bilalić et al. - 2010 - Mechanisms and neural basis of object and pattern .pdf},
  keywords = {Chess,Cognitions,Eye Movements,Functional Magnetic Resonance Imaging,Individual Differences,Insight,Object Recognition,Pattern Recognition (Cognitive Process)},
  number = {4}
}
% == BibLateX quality report for bilalic2010:
% Unexpected field 'publisher'
% Unexpected field 'location'

@inproceedings{chen2016,
  title = {Computer Vision Based Chess Playing Capabilities for the {{Baxter}} Humanoid Robot},
  booktitle = {International {{Conference}} on {{Control}}, {{Automation}} and {{Robotics}}},
  author = {Chen, Andrew Tzer-Yeu and Wang, Kevin I-Kai},
  date = {2016-04},
  pages = {11--14},
  abstract = {This paper presents a project that allows the Baxter humanoid robot to play chess against human players autonomously. The complete solution uses three main subsystems: computer vision based on a single camera embedded in Baxter's arm to perceive the game state, an open-source chess engine to compute the next move, and a mechatronics subsystem with a 7-DOF arm to manipulate the pieces. Baxter can play chess successfully in unconstrained environments by dynamically responding to changes in the environment. This implementation demonstrates Baxter's capabilities of vision-based adaptive control and small-scale manipulation, which can be applicable to numerous applications, while also contributing to the computer vision chess analysis literature.},
  eventtitle = {International {{Conference}} on {{Control}}, {{Automation}} and {{Robotics}}},
  file = {/Users/georg/Zotero/storage/NW2JUNT9/NW2JUNT9.pdf;/Users/georg/Zotero/storage/JQIYQEAN/7486689.html},
  keywords = {7-DOF arm,adaptive control,Baxter arm,Baxter humanoid robot,cameras,Cameras,chess robot,computer vision,Computer vision,computer vision based chess playing capabilities,dexterous manipulators,Engines,game state,grippers,human-robot interaction,humanoid robots,Image edge detection,mechatronics,Mechatronics,mechatronics subsystem,open-source chess engine,robot vision,Robot vision systems,single camera,small-scale manipulation,sport,two-finger gripper,unconstrained environments,uncontrolled environments,vision-based adaptive control}
}
% == BibLateX quality report for chen2016:
% ? Unsure about the formatting of the booktitle

@article{chen2019,
  title = {Robust {{Computer Vision Chess Analysis}} and {{Interaction}} with a {{Humanoid Robot}}},
  author = {Chen, Andrew Tzer-Yeu and Wang, Kevin I-Kai},
  date = {2019-03},
  journaltitle = {Computers},
  volume = {8},
  pages = {14},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  abstract = {As we move towards improving the skill of computers to play games like chess against humans, the ability to accurately perceive real-world game boards and game states remains a challenge in many cases, hindering the development of game-playing robots. In this paper, we present a computer vision algorithm developed as part of a chess robot project that detects the chess board, squares, and piece positions in relatively unconstrained environments. Dynamically responding to lighting changes in the environment, accounting for perspective distortion, and using accurate detection methodologies results in a simple but robust algorithm that succeeds 100\% of the time in standard environments, and 80\% of the time in extreme environments with external lighting. The key contributions of this paper are a dynamic approach to the Hough line transform, and a hybrid edge and morphology-based approach for object/occupancy detection, that enable the development of a robot chess player that relies solely on the camera for sensory input.},
  file = {/Users/georg/Zotero/storage/2IIDSADB/2IIDSADB.pdf;/Users/georg/Zotero/storage/JQV7VXXP/htm.html},
  issue = {1},
  keywords = {computer vision,human-robot interaction,image segmentation,mechatronics,morphological operations},
  langid = {english},
  number = {1}
}
% == BibLateX quality report for chen2019:
% Unexpected field 'publisher'
% ? Title looks like it was stored in title-case in Zotero

@report{cour2002,
  title = {Autonomous {{Chess}}-Playing {{Robot}}},
  author = {Cour, Timothée and Lauranson, Rémy and Vachette, Matthieu},
  date = {2002-07},
  institution = {{École Polytechnique}},
  location = {{Palaiseau, France}},
  url = {http://www.timotheecour.com/papers/ChessAutonomousRobot.pdf},
  file = {/Users/georg/Zotero/storage/HHJJC2BU/HHJJC2BU.pdf}
}
% == BibLateX quality report for cour2002:
% Missing required field 'type'

@inproceedings{czyzewski2018,
  title = {{{LATCHESS21}}: Dataset of Damaged Chessboard Lattice Points (Chessboard Features) Used to Train {{LAPS}} Detector (Grayscale/21x21px)},
  shorttitle = {{{LATCHESS21}}},
  author = {Czyzewski, Maciej A. and Laskowski, Artur and Wasik, Szymon},
  date = {2018},
  publisher = {{RepOD}},
  abstract = {LATCHESS21: dataset of damaged chessboard lattice points (chessboard features) used to train LAPS detector (grayscale/21x21px)}
}
% == BibLateX quality report for czyzewski2018:
% Missing required field 'booktitle'

@online{czyzewski2020,
  title = {Chessboard and Chess Piece Recognition with the Support of Neural Networks},
  author = {Czyzewski, Maciej A. and Laskowski, Artur and Wasik, Szymon},
  date = {2020-06-23},
  abstract = {Chessboard and chess piece recognition is a computer vision problem that has not yet been efficiently solved. However, its solution is crucial for many experienced players who wish to compete against AI bots, but also prefer to make decisions based on the analysis of a physical chessboard. It is also important for organizers of chess tournaments who wish to digitize play for online broadcasting or ordinary players who wish to share their gameplay with friends. Typically, such digitization tasks are performed by humans or with the aid of specialized chessboards and pieces. However, neither solution is easy or convenient. To solve this problem, we propose a novel algorithm for digitizing chessboard configurations. We designed a method that is resistant to lighting conditions and the angle at which images are captured, and works correctly with numerous chessboard styles. The proposed algorithm processes pictures iteratively. During each iteration, it executes three major sub-processes: detecting straight lines, finding lattice points, and positioning the chessboard. Finally, we identify all chess pieces and generate a description of the board utilizing standard notation. For each of these steps, we designed our own algorithm that surpasses existing solutions. We support our algorithms by utilizing machine learning techniques whenever possible. The described method performs extraordinarily well and achieves an accuracy over \$99.5\textbackslash\%\$ for detecting chessboard lattice points (compared to the \$74\textbackslash\%\$ for the best alternative), \$95\textbackslash\%\$ (compared to \$60\textbackslash\%\$ for the best alternative) for positioning the chessboard in an image, and almost \$95\textbackslash\%\$ for chess piece recognition.},
  archivePrefix = {arXiv},
  eprint = {1708.03898},
  eprinttype = {arxiv},
  file = {/Users/georg/Zotero/storage/AZA3P2FH/AZA3P2FH.pdf;/Users/georg/Zotero/storage/S6R2BDY3/1708.html},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}
% == BibLateX quality report for czyzewski2020:
% Unexpected field 'archivePrefix'

@online{danner2015,
  title = {Visual {{Chess Recognition}}},
  author = {Danner, Cheryl and Kafafy, Mai},
  date = {2015},
  url = {https://web.stanford.edu/class/ee368/Project_Spring_1415/Reports/Danner_Kafafy.pdf},
  abstract = {In this paper, we correctly detect and identify a chessboard and the configuration of its pieces through the application of image processing. While more technically challenging, the use of image processing to detect and identify a chessboard and the configuration of its pieces avoids the need for a digital chess set. Furthermore, image-based detection of chess pieces is a vital step in building chess-playing robots.},
  file = {/Users/georg/Zotero/storage/X8C2GS97/X8C2GS97.pdf},
  langid = {english}
}
% == BibLateX quality report for danner2015:
% ? Title looks like it was stored in title-case in Zotero

@article{delaescalera2010,
  title = {Automatic {{Chessboard Detection}} for {{Intrinsic}} and {{Extrinsic Camera Parameter Calibration}}},
  author = {De la Escalera, Arturo and Armingol, Jose María},
  date = {2010-03},
  journaltitle = {Sensors},
  volume = {10},
  pages = {2027--2044},
  publisher = {{Molecular Diversity Preservation International}},
  abstract = {There are increasing applications that require precise calibration of cameras to perform accurate measurements on objects located within images, and an automatic algorithm would reduce this time consuming calibration procedure. The method proposed in this article uses a pattern similar to that of a chess board, which is found automatically in each image, when no information regarding the number of rows or columns is supplied to aid its detection. This is carried out by means of a combined analysis of two Hough transforms, image corners and invariant properties of the perspective transformation. Comparative analysis with more commonly used algorithms demonstrate the viability of the algorithm proposed, as a valuable tool for camera calibration.},
  file = {/Users/georg/Zotero/storage/MHAN678P/De la Escalera and Armingol - 2010 - Automatic Chessboard Detection for Intrinsic and E.pdf},
  issue = {3},
  keywords = {camera calibration,chessboard detection,double Hough transform,pattern recognition},
  langid = {english},
  number = {3}
}
% == BibLateX quality report for delaescalera2010:
% Unexpected field 'publisher'
% ? Title looks like it was stored in title-case in Zotero

@online{ding2016,
  title = {{{ChessVision}} : {{Chess Board}} and {{Piece Recognition}}},
  shorttitle = {{{ChessVision}}},
  author = {Ding, J.},
  date = {2016},
  url = {https://web.stanford.edu/class/cs231a/prev_projects_2016/CS_231A_Final_Report.pdf},
  abstract = {This paper details a method to take an image of a chess board and output a reconstructed computer representation of the board through board and piece recognition. Though techniques for board recognition have been thoroughly explored in the past, especially in relation to chessboard calibration, previous works on piece recognition often focus on non-robust segmentation procedures that rely heavily on the exact color of customized chess boards and pieces. The method presented in this paper improves upon the segmentation-based approaches of previous work in piece recognition by introducing a novel approach using classifiers trained on feature descriptors, which is more robust to the similarities in color seen in real-life chess boards. This work is important for both automating the recording of moves in human chess games and improving the ability of chess-playing AI that depend on vision.},
  file = {/Users/georg/Zotero/storage/Y7VJH2YW/Y7VJH2YW.pdf},
  langid = {english}
}
% == BibLateX quality report for ding2016:
% ? Title looks like it was stored in title-case in Zotero

@book{edwards1994,
  title = {{{PGN Standard}}},
  author = {Edwards, Steven J.},
  date = {1994-03-12},
  url = {http://archive.org/details/pgn-standard-1994-03-12},
  abstract = {Portable Game Notation Specification and Implementation Guide},
  keywords = {chess},
  langid = {english}
}
% == BibLateX quality report for edwards1994:
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{goncalves2005,
  title = {Chess Robot System : A Multi-Disciplinary Experience in Automation},
  shorttitle = {Chess Robot System},
  booktitle = {Spanish {{Portuguese Congress}} on {{Electrical Engineering}}},
  author = {Gonçalves, José and Lima, José and Leitão, Paulo},
  date = {2005},
  abstract = {This paper describes a chess robot system that allows remote users to play chess, using a six axes anthropomorphic robot to move chess pieces in the chessboard on getting commands from the player  and from the application chess engine. This experience allowed applying the concept of 'learning by doing', involving the integration of multi-disciplinary skills and teams.},
  annotation = {Accepted: 2010-02-12T17:20:43Z},
  eventtitle = {Spanish {{Portuguese Congress}} on {{Electrical Engineering}}},
  file = {/Users/georg/Zotero/storage/HVZYNFYL/HVZYNFYL.pdf},
  langid = {english}
}
% == BibLateX quality report for goncalves2005:
% ? Unsure about the formatting of the booktitle

@book{goodfellow2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  publisher = {{MIT Press}}
}

@report{hack2014,
  title = {{{CVChess}}: {{Computer Vision Chess Analytics}}},
  author = {Hack, Jay and Ramakrishnan, Prithvi},
  date = {2014},
  institution = {{Stanford University}},
  url = {https://web.stanford.edu/class/cs231a/prev_projects_2015/chess.pdf},
  abstract = {We present a computer vision application and a set of associated algorithms capable of recording chess game moves fully autonomously from the vantage point of a consumer laptop webcam. This consists of two main algorithms, (1) a hough transform-based algorithm for finding a homography relating board coordinates to image coordinates, and (2) a model of chessboard colors and occlusions that allows us to account for and infer piece movement in real time. We provide a video demonstration of the application applied to a real chess game and describe experiments in which our developed algorithms significantly outperform a naive baseline. All code is open sourced and available on GitHub.},
  file = {/Users/georg/Zotero/storage/SNSHYGUK/SNSHYGUK.pdf},
  langid = {english}
}
% == BibLateX quality report for hack2014:
% Missing required field 'type'
% ? Title looks like it was stored in title-case in Zotero

@report{hou,
  title = {Chessman {{Position Recognition Using Artificial Neural Networks}}},
  author = {Hou, Jun},
  abstract = {In the augmented reality chess game, a human user plays chess with a virtual user. To do realtime registration, the positions of the black chess pieces have to be found whenever the real world user makes a move. A Feed Forward Artificial Neural Network is used to recognize the chess piece positions. For training, images are acquired by synthesizing the chessboard and the pieces from different perspectives for different chess piece positions. To normalize the chessboard image with different perspectives, the chessboard corners are found and each chessboard square is divided into 8*8 smaller squares. Several variations of Gradient Descent algorithms in Back Propagation are examined. Although there is still much work to be done, the ANN approach has revealed its convenience and performance in this task. 1.},
  file = {/Users/georg/Zotero/storage/2GKJGMBC/Hou - Chessman Position Recognition Using Artificial Neu.pdf}
}
% == BibLateX quality report for hou:
% Exactly one of 'date' / 'year' must be present
% Missing required field 'type'
% Missing required field 'institution'
% ? Title looks like it was stored in title-case in Zotero

@article{kanchibail2016,
  title = {Chess {{Board Recognition}}},
  author = {Kanchibail, Raghuveer and Suryaprakash, Supreeth and Jagadish, Suhas},
  date = {2016},
  url = {http://vision.soic.indiana.edu/b657/sp2016/projects/rkanchib/paper.pdf},
  abstract = {Chess Board recognition is an implementation which recognizes the chess board by locating the squares and detect the chess pieces from the input image using image processing techniques. The chess board is segmented from the input image, edges are detected using Canny’s edge detector and cross lines are detected using Hough transform. This will give us the required 64 squares. Each square, with some vicinity around it, is extracted and compared to see if it contains a chess piece. If yes, then the test piece is scaled and oriented to compare with the pre-defined training set. The area score is calculated by taking difference of training pieces and test piece and the one with the lowest score is chosen as the best matching piece.},
  file = {/Users/georg/Zotero/storage/NA9G2PZ9/NA9G2PZ9.pdf}
}
% == BibLateX quality report for kanchibail2016:
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@book{kasparov2018,
  title = {Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins},
  shorttitle = {Deep Thinking},
  author = {Kasparov, Garry and Greengard, Mig},
  date = {2018},
  annotation = {OCLC: 1083948333},
  isbn = {978-1-4736-5351-1},
  langid = {english}
}

@article{khan2014,
  title = {Design and Development of Autonomous Chess Playing Robot},
  author = {Khan, R Arif Mohamed and Kesavan, R},
  date = {2014},
  journaltitle = {International Journal of Innovative Science, Engineering \& Technology},
  volume = {1},
  file = {/Users/georg/Zotero/storage/KU32YVT4/KU32YVT4.pdf},
  number = {1}
}

@inproceedings{khater2012,
  title = {Chessboard Recognition System Using Signature, Principal Component Analysis and Color Information},
  booktitle = {International {{Conference}} on {{Digital Information Processing}} and {{Communications}}},
  author = {Khater, Ismail M. and Ghorab, Ahmed S. and Aljarrah, Inad A.},
  date = {2012-07},
  pages = {141--145},
  abstract = {This paper aims to implement a computer vision technique to translate an image into a description that can be read by computer programs to make decisions. The proposed system is applied to chessboard with a set of objects (pieces), and outputs the pieces names, locations, in addition to the pieces' colors. The signature feature has been used to distinguish the pieces types but when the signature comes to grief, the PCA (Principal Components Analysis) is used, and then the object color is obtained. The proposed system was trained and tested using Matlab, based on a set of collected samples using chessboard images. The simulation results show the effectiveness of the proposed method to recognize the pieces locations, types, and colors.},
  eventtitle = {International {{Conference}} on {{Digital Information Processing}} and {{Communications}}},
  file = {/Users/georg/Zotero/storage/6RHCCFAJ/6RHCCFAJ.pdf;/Users/georg/Zotero/storage/KR6VM9MY/6257285.html},
  keywords = {Chess,chessboard images,chessboard recognition system,color information,computer vision,Computer vision,Computer Vision,computer vision technique,Educational institutions,Euclidean distance,Euclidean Distance,feature extraction,Feature extraction,Image color analysis,image colour analysis,Matlab,Noise,object color,object recognition,PCA,piece color recognition,piece location recognition,piece type recognition,principal component analysis,Principal component analysis,signature feature,Signature Feature}
}
% == BibLateX quality report for khater2012:
% ? Unsure about the formatting of the booktitle

@article{krizhevsky2017,
  title = {{{ImageNet}} Classification with Deep Convolutional Neural Networks},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  date = {2017-05-24},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {60},
  pages = {84--90},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  file = {/Users/georg/Zotero/storage/2IKLDZ6R/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf},
  number = {6}
}

@inproceedings{matuszek2011,
  title = {Gambit: {{An}} Autonomous Chess-Playing Robotic System},
  shorttitle = {Gambit},
  booktitle = {{{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Matuszek, Cynthia and Mayton, Brian and Aimi, Roberto and Deisenroth, Marc Peter and Bo, Liefeng and Chu, Robert and Kung, Mike and LeGrand, Louis and Smith, Joshua R. and Fox, Dieter},
  date = {2011-05},
  pages = {4291--4297},
  abstract = {This paper presents Gambit, a custom, mid-cost 6-DoF robot manipulator system that can play physical board games against human opponents in non-idealized environments. Historically, unconstrained robotic manipulation in board games has often proven to be more challenging than the underlying game reasoning, making it an ideal testbed for small-scale manipulation. The Gambit system includes a low-cost Kinect-style visual sensor, a custom manipulator, and state-of-the-art learning algorithms for automatic detection and recognition of the board and objects on it. As a use-case, we describe playing chess quickly and accurately with arbitrary, uninstrumented boards and pieces, demonstrating that Gambit's engineering and design represent a new state-of-the-art in fast, robust tabletop manipulation.},
  eventtitle = {{{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  file = {/Users/georg/Zotero/storage/JGF8543C/JGF8543C.pdf;/Users/georg/Zotero/storage/24VZUPHE/5980528.html},
  keywords = {automatic board detection,automatic object detection,automatic object recognition,autonomous chess-playing robotic system,Cameras,Detectors,dexterous manipulators,Gambit robotic system,game reasoning,Games,Humans,Image color analysis,inference mechanisms,learning (artificial intelligence),low-cost Kinect-style visual sensor,manipulator kinematics,Mechanism Design of Manipulators,nonidealized environment,object detection,object recognition,physical board games,Physical Human Robot Interaction,Robot sensing systems,robot vision,robust tabletop manipulation,six-DoF robot manipulator system,small-scale manipulation,state-of-the-art learning algorithm,unconstrained robotic manipulation}
}
% == BibLateX quality report for matuszek2011:
% ? Unsure about the formatting of the booktitle

@article{mehta2020,
  title = {Augmented {{Reality Chess Analyzer}} ({{ARChessAnalyzer}}): {{In}}-{{Device Inference}} of {{Physical Chess Game Positions}} through {{Board Segmentation}} and {{Piece Recognition}} Using {{Convolutional Neural Networks}}},
  shorttitle = {Augmented {{Reality Chess Analyzer}} ({{ARChessAnalyzer}})},
  author = {Mehta, Anav and Mehta, Huzefa},
  date = {2020-07-17},
  journaltitle = {Journal of Emerging Investigators},
  abstract = {Chess game position analysis is important in improving ones game. It requires entry of moves into a chess engine which is, cumbersome and error prone. We present ARChessAnalyzer, a complete pipeline from live image capture of a physical chess game, to board and piece recognition, to move analysis and finally to Augmented Reality (AR) overlay of the chess diagram position and move on the physical board. ARChessAnalyzer is like a scene analyzer - it uses an ensemble of traditional image and vision techniques to segment the scene (ie the chess game) and uses Convolution Neural Networks (CNNs) to predict the segmented pieces and combine it together to analyze the game. This paper advances the state of the art in the first of its kind end to end integration of robust detection and segmentation of the board, chess piece detection using the fine-tuned AlexNet CNN and chess engine analyzer in a handheld device app. The accuracy of the entire chess position prediction pipeline is 93.45\textbackslash\% and takes 3-4.5sec from live capture to AR overlay. We also validated our hypothesis that ARChessAnalyzer, is faster at analysis than manual entry for all board positions for valid outcomes. Our hope is that the instantaneous feedback this app provides will help chess learners worldwide at all levels improve their game.},
  file = {/Users/georg/Zotero/storage/3TMWTWFK/3TMWTWFK.pdf},
  keywords = {Computer Science - Human-Computer Interaction}
}

@inproceedings{neufeld2010,
  title = {Probabilistic Location of a Populated Chessboard Using Computer Vision},
  booktitle = {{{IEEE International Midwest Symposium}} on {{Circuits}} and {{Systems}}},
  author = {Neufeld, Jason E. and Hall, Tyson S.},
  date = {2010-08},
  pages = {616--619},
  abstract = {Development of autonomic chess-playing robots creates several interesting computer vision problems, including plane calibration and object recognition. Various solutions have been attempted, but most either require a modified chess set or place unreasonable constraints on board conditions and camera angles. A more general solution uses computer vision to automatically determine arbitrary chessboard location and identify chessmen on a standard, unmodified chess set. Although much work has been devoted to probabilistic image recognition in general, this paper presents a novel solution to the specific chessboard location problem that is accurate, less restrictive, and relatively time efficient.},
  eventtitle = {{{IEEE International Midwest Symposium}} on {{Circuits}} and {{Systems}}},
  file = {/Users/georg/Zotero/storage/YENCMSEI/YENCMSEI.pdf;/Users/georg/Zotero/storage/2J96EJBN/citations.html},
  keywords = {Calibration,Cameras,Chess,chess playing robots,computer vision,Computer vision,Educational institutions,Games,Humans,image recognition,Image recognition,intelligent robots,Machine vision,object recognition,Object recognition,plane calibration,populated chessboard,probabilistic location,robot vision,Robot vision systems,Robotics and automation}
}
% == BibLateX quality report for neufeld2010:
% ? Unsure about the formatting of the booktitle

@software{romstad2020,
  title = {Stockfish},
  author = {Romstad, Tord and Costalba, Marco and Kiiski, Joona},
  date = {2020-09-23T20:03:08Z},
  origdate = {2014-06-18T19:59:53Z},
  url = {https://github.com/official-stockfish/Stockfish},
  abstract = {UCI chess engine. Contribute to official-stockfish/Stockfish development by creating an account on GitHub.}
}
% == BibLateX quality report for romstad2020:
% Unexpected field 'title'
% Unexpected field 'author'

@software{roy2020,
  title = {Chessputzer},
  author = {Roy, Abhishek},
  date = {2020-07-12T17:29:53Z},
  origdate = {2017-11-16T13:25:09Z},
  url = {https://github.com/metterklume/chessputzer},
  abstract = {Image recognition for chess positions. Contribute to metterklume/chessputzer development by creating an account on GitHub.}
}
% == BibLateX quality report for roy2020:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@software{sameer2020,
  title = {Tensorflow\_chessbot},
  author = {Sameer, Ansari},
  date = {2020-09-06T06:59:21Z},
  origdate = {2016-02-08T09:52:24Z},
  url = {https://github.com/Elucidation/tensorflow_chessbot},
  abstract = {Predict chessboard FEN layouts from images using TensorFlow},
  keywords = {chess,chessboard,chessboard-detection,chessboard-recognition,tensorflow,tensorflow-examples,tensorflow-tutorials}
}
% == BibLateX quality report for sameer2020:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@inproceedings{sokic2008,
  title = {Simple {{Computer Vision System}} for {{Chess Playing Robot Manipulator}} as a {{Project}}-Based {{Learning Example}}},
  booktitle = {{{IEEE International Symposium}} on {{Signal Processing}} and {{Information Technology}}},
  author = {Sokic, Emir and Ahic-Djokic, Melita},
  date = {2008-12},
  pages = {75--79},
  abstract = {This paper presents an example of project-based learning (PBL) in an undergraduate course on Image processing. The design of a simple, low-cost computer vision system for implementation on a chess-playing capable robot is discussed. The system is based on a standard CCD camera and a personal computer. This project is a good tool for learning most of the course material that would otherwise be mastered by homework problems and study before an exam. An algorithm which detects chess moves is proposed. It compares two or more frames captured before, during and after a played chess move, and finds differences between them, which are used to define a played chess move. Further image processing is required to eliminate false readings, recognize direction of chess moves, end eliminate image distortion. Many Image processing problems and solutions can be introduced to students, through the proposed algorithm. The results are encouraging - students without any previous knowledge in image processing and advanced topics, such as artificial intelligence (neural networks etc.), may attain a chess move recognition success rate greater than 95\%, in controlled light environments.},
  eventtitle = {{{IEEE International Symposium}} on {{Signal Processing}} and {{Information Technology}}},
  file = {/Users/georg/Zotero/storage/AB75JXK3/AB75JXK3.pdf;/Users/georg/Zotero/storage/CZYM7VRA/4775676.html},
  keywords = {artificial intelligence,Cameras,CCD camera,Charge coupled devices,Charge-coupled image sensors,chess moves recognition,chess playing robot manipulator,computer vision,Computer vision,computer vision system,Educational robots,image distortion,image processing,Image processing,Image recognition,learning (artificial intelligence),manipulators,Manipulators,Process design,project-based learning,robot manipulator,Robot vision systems}
}
% == BibLateX quality report for sokic2008:
% ? Unsure about the formatting of the booktitle

@incollection{szeliski2011,
  title = {Image Formation},
  booktitle = {Computer {{Vision}}: {{Algorithms}} and {{Applications}}},
  author = {Szeliski, Richard},
  date = {2011},
  pages = {27--86},
  publisher = {{Springer}},
  location = {{London}},
  abstract = {Before we can intelligently analyze and manipulate images, we need to establish a vocabulary for describing the geometry of a scene. We also need to understand the image formation process that produced a particular image given a set of lighting conditions, scene geometry, surface properties, and camera optics. In this chapter, we present a simplified model of such an image formation process},
  isbn = {978-1-84882-935-0},
  keywords = {Chromatic Aberration,Discrete Cosine Transform,Focal Length,Image Formation,Point Spread Function},
  langid = {english}
}
% == BibLateX quality report for szeliski2011:
% Missing required field 'editor'

@inproceedings{tam2008,
  title = {Automatic {{Grid Segmentation}} of {{Populated Chessboard Taken}} at a {{Lower Angle View}}},
  booktitle = {Digital {{Image Computing}}: {{Techniques}} and {{Applications}}},
  author = {Tam, K.Y. and Lay, J.A. and Levy, D.},
  date = {2008-12},
  pages = {294--299},
  abstract = {Segmentation of the chessboard grid is a crucial step in coordinate extraction for chess video annotation, content-based indexing of chess videos and for content analysis in prototyping vision systems such as a chess robot. This paper deals with the segmentation of grid elements from a populated chessboard taken at a lower angle view. The proposed approach couples the line-based grid detection method with domain knowledge of the chessboard to achieve improved accuracy and reliability.},
  eventtitle = {Digital {{Image Computing}}: {{Techniques}} and {{Applications}}},
  file = {/Users/georg/Zotero/storage/UKKUZ63K/UKKUZ63K.pdf;/Users/georg/Zotero/storage/MATIHE7Z/4700034.html},
  keywords = {automatic grid segmentation,chess,chess robot,chess video annotation,Computer applications,Computer vision,content-based indexing,Design engineering,Detectors,Digital images,edge detection,Games,Grid computing,grid detection,image segmentation,Image segmentation,Indexing,line-based grid detection method,lower angle view,populated chessboard,Video equipment,vision system}
}
% == BibLateX quality report for tam2008:
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{urting2003,
  title = {{{MarineBlue}}: {{A}} Low-Cost Chess Robot},
  booktitle = {International Conference Robotics and Applications},
  author = {Urting, David and Berbers, Yolande},
  date = {2003-06},
  pages = {76--81},
  location = {{Salzburg, Austria}},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/ra/UrtingB03.bib},
  eventtitle = {International Conference Robotics and Applications},
  file = {/Users/georg/Zotero/storage/76VZEI2M/76VZEI2M.pdf},
  timestamp = {Thu, 30 Oct 2003 07:57:45 +0100}
}
% == BibLateX quality report for urting2003:
% Unexpected field 'bibsource'
% Unexpected field 'biburl'
% Unexpected field 'timestamp' (added because JabRef format is set to ?)
% ? Unsure about the formatting of the booktitle

@inproceedings{wang2013,
  title = {Chess Move Tracking Using Overhead {{RGB}} Webcam},
  booktitle = {International {{Conference}} on {{Image}} and {{Vision Computing New Zealand}}},
  author = {Wang, Victor and Green, Richard},
  date = {2013-11},
  pages = {299--304},
  abstract = {This paper proposes a real-time application for detecting the moves of a chess game given a video stream from a camera positioned over the board. A custom implementation based on square identification of flood filled regions is used to detect colored chessboards in arbitrary backgrounds. The detected board is transformed to a normalized image, and occupancy of the chessboard is determined by classifying the pixels within each square of the 8×8 grid to check for a piece of a given color. A move is recognized when the current occupancy grid matches the chessboard that results from one of the possible moves from the previous occupancy grid. These moves and occupancy grids are supplied by a chess engine. A simple motion detection method is used to avoid processing frames in which a player is obscuring any part of the board. It uses hysteretic n-frame thresholding of difference images.},
  eventtitle = {International {{Conference}} on {{Image}} and {{Vision Computing New Zealand}}},
  file = {/Users/georg/Zotero/storage/XZKJQBGL/XZKJQBGL.pdf;/Users/georg/Zotero/storage/8P2VWIG4/6727033.html},
  keywords = {camera,Cameras,chess game,chess move tracking,chessboard color detection,computer games,flood fill square detection,Floods,Games,grid matches,Image color analysis,image sensors,Lighting,motion detection method,motion estimation,n-frame hysteretic motion filter,object tracking,overhead RGB Webcam,real-time application,real-time chess move detection,Robots,Robustness,square identification,video stream,video streaming}
}
% == BibLateX quality report for wang2013:
% ? Unsure about the formatting of the booktitle

@inproceedings{wei2017,
  title = {Chess Recognition from a Single Depth Image},
  booktitle = {{{IEEE International Conference}} on {{Multimedia}} and {{Expo}}},
  author = {Wei, Yu-An and Huang, Tzu-Wei and Chen, Hwann-Tzong and Liu, JenChi},
  date = {2017-07},
  pages = {931--936},
  abstract = {This paper presents a learning-based method for recognizing chess pieces from depth information. The proposed method is integrated in a recreational robotic system that is designed to play games of chess against humans. The robot has two arms and an Ensenso N35 Stereo 3D camera. Our goal is to provide the robot visual intelligence so that it can identify the chess pieces on the chessboard using the depth information captured by the 3D camera. We build a convolutional neural network to solve this 3D object recognition problem. While training neural networks for 3D object recognition becomes popular these days, collecting enough training data is still a time-consuming task. We demonstrate that it is much more convenient and effective to generate the required training data from 3D CAD models. The neural network trained using the rendered data performs well on real inputs during testing. More specifically, the experimental results show that using the training data rendered from the CAD models under various conditions enhances the recognition accuracy significantly. When further evaluations are done on real data captured by the 3D camera, our method achieves 90.3\% accuracy.},
  eventtitle = {{{IEEE International Conference}} on {{Multimedia}} and {{Expo}}},
  file = {/Users/georg/Zotero/storage/KUJJZ7KS/KUJJZ7KS.pdf;/Users/georg/Zotero/storage/KN8VKTTK/8019453.html},
  keywords = {3D CAD models,3D object recognition,3D object recognition problem,CAD,Cameras,chess pieces,chess recognition,convolutional neural network,convolutional neural networks,depth information,Ensenso N35 Stereo 3D camera,feedforward neural nets,learning (artificial intelligence),learning-based method,object recognition,Object recognition,recreational robotic system,robot vision,robot visual intelligence,Robots,single depth image,Solid modeling,solid modelling,stereo image processing,Three-dimensional displays,Training data,volumetric representation}
}
% == BibLateX quality report for wei2017:
% ? Unsure about the formatting of the booktitle

@inproceedings{xie2018,
  title = {Chess {{Piece Recognition Using Oriented Chamfer Matching}} with a {{Comparison}} to {{CNN}}},
  booktitle = {{{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  author = {Xie, Youye and Tang, Gongguo and Hoff, William},
  date = {2018-03},
  pages = {2001--2009},
  abstract = {Recognizing three dimensional chess pieces using computer vision is needed for an augmented reality chess assistant. This paper proposes an efficient 3D pieces recognition approach based on oriented chamfer matching. During a real game, the pieces might be occluded by other pieces and have varying rotation and scales with respect to the camera. Furthermore, different pieces share lots of similar texture features which makes them more difficult to identify. Our approach addresses the above problems and is capable of identifying the pieces with different scales, rotation and viewing angles. After marking the possible chessboard squares that contain pieces, the oriented chamfer scores are calculated for alternative templates and the recognized pieces are indicated on the input image accordingly. Our approach shows high recognition accuracy and efficiency in experiments and the recognition process can be easily generalized to other pattern recognition applications with 3D templates. Our approach outperforms the convolutional neural networks under severe occlusion and low resolution conditions and has comparative processing time while avoids the time consuming training process.},
  eventtitle = {{{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  file = {/Users/georg/Zotero/storage/78AK3KIJ/78AK3KIJ.pdf;/Users/georg/Zotero/storage/4LZXSLEJ/8354325.html},
  keywords = {3D pieces recognition approach,augmented reality,augmented reality chess assistant,Cameras,chessboard squares,computer vision,convolutional neural networks,feature extraction,Feature extraction,feedforward neural nets,Games,high recognition accuracy,Image color analysis,Image edge detection,image matching,image texture,object detection,oriented chamfer matching,oriented chamfer scores,texture features,three dimensional chess piece recognition,Three-dimensional displays}
}
% == BibLateX quality report for xie2018:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{xie2018a,
  title = {Geometry-Based Populated Chessboard Recognition},
  booktitle = {International {{Conference}} on {{Machine Vision}}},
  author = {Xie, Youye and Tang, Gongguo and Hoff, William},
  date = {2018-04-13},
  volume = {10696},
  pages = {1069603},
  publisher = {{International Society for Optics and Photonics}},
  abstract = {Chessboards are commonly used to calibrate cameras, and many robust methods have been developed to recognize the unoccupied boards. However, when the chessboard is populated with chess pieces, such as during an actual game, the problem of recognizing the board is much harder. Challenges include occlusion caused by the chess pieces, the presence of outlier lines and low viewing angles of the chessboard. In this paper, we present a novel approach to address the above challenges and recognize the chessboard. The Canny edge detector and Hough transform are used to capture all possible lines in the scene. The k-means clustering and a k-nearest-neighbors inspired algorithm are applied to cluster and reject the outlier lines based on their Euclidean distances to the nearest neighbors in a scaled Hough transform space. Finally, based on prior knowledge of the chessboard structure, a geometric constraint is used to find the correspondences between image lines and the lines on the chessboard through the homography transformation. The proposed algorithm works for a wide range of the operating angles and achieves high accuracy in experiments.},
  eventtitle = {International {{Conference}} on {{Machine Vision}}},
  file = {/Users/georg/Zotero/storage/2A5PFNWV/2A5PFNWV.pdf}
}
% == BibLateX quality report for xie2018a:
% ? Unsure about the formatting of the booktitle

@online{zhou2018,
  title = {Pattern Recognition in Chess},
  author = {Zhou, Qiyu},
  date = {2018-05-30},
  journaltitle = {ChessBase},
  url = {https://en.chessbase.com/post/pattern-recognition-in-chess},
  abstract = {Is there a correlation between the strength in chess of players and their ability to recall a position in chess using short-term memory? This was the research question of a budding young scientist, QIYU ZHOU, who gave professional and casual chess players positions to study and then attempt to reconstruct them within 30 seconds. Her results are meticulously documented in a paper we are pleased to publish. At the end, there is an appeal to our readers to help with associated material.},
  langid = {english}
}
% == BibLateX quality report for zhou2018:
% Unexpected field 'journaltitle'


