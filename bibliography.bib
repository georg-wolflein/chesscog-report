
@online{64squares2020,
  title = {Magnus {{Carlsen Chess Games}}},
  author = {{64 Squares}},
  date = {2020-02},
  url = {https://www.pgnmentor.com/players/Carlsen/},
  organization = {{PGN Mentor}}
}
% == BibLateX quality report for 64squares2020:
% ? Title looks like it was stored in title-case in Zotero

@online{acher2016,
  title = {Large-Scale {{Analysis}} of {{Chess Games}} with {{Chess Engines}}: {{A Preliminary Report}}},
  shorttitle = {Large-Scale {{Analysis}} of {{Chess Games}} with {{Chess Engines}}},
  author = {Acher, Mathieu and Esnault, François},
  date = {2016-04-28},
  abstract = {The strength of chess engines together with the availability of numerous chess games have attracted the attention of chess players, data scientists, and researchers during the last decades. State-of-the-art engines now provide an authoritative judgement that can be used in many applications like cheating detection, intrinsic ratings computation, skill assessment, or the study of human decision-making. A key issue for the research community is to gather a large dataset of chess games together with the judgement of chess engines. Unfortunately the analysis of each move takes lots of times. In this paper, we report our effort to analyse almost 5 millions chess games with a computing grid. During summer 2015, we processed 270 millions unique played positions using the Stockfish engine with a quite high depth (20). We populated a database of 1+ tera-octets of chess evaluations, representing an estimated time of 50 years of computation on a single machine. Our effort is a first step towards the replication of research results, the supply of open data and procedures for exploring new directions, and the investigation of software engineering/scalability issues when computing billions of moves.},
  archivePrefix = {arXiv},
  eprint = {1607.04186},
  eprinttype = {arxiv},
  file = {/Users/georg/Zotero/storage/VK282A6H/Acher and Esnault - 2016 - Large-scale Analysis of Chess Games with Chess Eng.pdf;/Users/georg/Zotero/storage/EA895GBW/1607.html},
  keywords = {Computer Science - Artificial Intelligence}
}
% == BibLateX quality report for acher2016:
% Unexpected field 'archivePrefix'

@article{baird1990,
  title = {Reading Chess},
  author = {Baird, H.S. and Thompson, K.},
  date = {1990-06},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {12},
  pages = {552--559},
  abstract = {By applying semantic analysis to images of extended passages of text, several volumes of a chess encyclopedia have been read with high accuracy. Although carefully proofread, the books were poorly printed and posed a severe challenge to conventional page-layout analysis and character-recognition methods. An experimental page-reader system performed strictly top-down layout analysis for identification of columns, lines, words, and characters. This proceeded rapidly and reliably thanks to a recently developed skew-estimation technique. Resegmentation of broken, touching, and dirty characters was handled in an efficient and integrated manner by a heuristic search operating on isolated words. By analyzing the syntax of game descriptions and applying the rules of chess, the error rate was reduced by a factor of 30 from what was achievable through shape analysis alone. Several computer vision systems integration issues suggested by this experience are discussed.{$<>$}},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  file = {/Users/georg/Zotero/storage/WARIFC45/Baird and Thompson - 1990 - Reading chess.pdf;/Users/georg/Zotero/storage/3JNWKN5V/56191.html},
  keywords = {Books,character recognition,character-recognition,chess reading,computer vision,Computer vision,Encyclopedias,Error analysis,heuristic search,Image analysis,page-reader system,Performance analysis,semantic analysis,Shape,skew-estimation},
  number = {6}
}
% == BibLateX quality report for baird1990:
% Unexpected field 'eventtitle'

@inproceedings{banerjee2012,
  title = {A {{Simple Autonomous Chess Playing Robot}} for Playing {{Chess}} against Any Opponent in {{Real Time}}},
  booktitle = {International {{Conference}} on {{Computational Vision}} and {{Robotics}}},
  author = {Banerjee, Nandan and Saha, Debal and Singh, Atikant and Sanyal, Gautam},
  date = {2012-08},
  volume = {58},
  pages = {17--22},
  publisher = {{Interscience Research Network}},
  location = {{Bhubaneshwar, India}},
  eventtitle = {International {{Conference}} on {{Computational Vision}} and {{Robotics}}},
  file = {/Users/georg/Zotero/storage/GVGX8VH9/GVGX8VH9.pdf}
}
% == BibLateX quality report for banerjee2012:
% ? Unsure about the formatting of the booktitle

@article{bennett2014,
  title = {{{ChESS}} – {{Quick}} and Robust Detection of Chess-Board Features},
  author = {Bennett, Stuart and Lasenby, Joan},
  date = {2014-01-01},
  journaltitle = {Computer Vision and Image Understanding},
  shortjournal = {Computer Vision and Image Understanding},
  volume = {118},
  pages = {197--210},
  abstract = {Localization of chess-board vertices is a common task in computer vision, underpinning many applications, but relatively little work focusses on designing a specific feature detector that is fast, accurate and robust. In this paper the ‘Chess-board Extraction by Subtraction and Summation’ (ChESS) feature detector, designed to exclusively respond to chess-board vertices, is presented. The method proposed is robust against noise, poor lighting and poor contrast, requires no prior knowledge of the extent of the chess-board pattern, is computationally very efficient, and provides a strength measure of detected features. Such a detector has significant application both in the key field of camera calibration, as well as in structured light 3D reconstruction. Evidence is presented showing its superior robustness, accuracy, and efficiency in comparison to other commonly used detectors, including Harris \& Stephens and SUSAN, both under simulation and in experimental 3D reconstruction of flat plate and cylindrical objects.},
  file = {/Users/georg/Zotero/storage/4T6K8GSE/4T6K8GSE.pdf;/Users/georg/Zotero/storage/IESL7ENN/S1077314213001999.html},
  keywords = {Camera calibration,Chess-board corner detection,Feature extraction,Pattern recognition,Photogrammetric marker detection,Structured light surface measurement},
  langid = {english}
}

@article{bilalic2010,
  title = {Mechanisms and Neural Basis of Object and Pattern Recognition: {{A}} Study with Chess Experts},
  shorttitle = {Mechanisms and Neural Basis of Object and Pattern Recognition},
  author = {Bilalić, Merim and Langner, Robert and Erb, Michael and Grodd, Wolfgang},
  date = {2010},
  journaltitle = {Journal of Experimental Psychology},
  volume = {139},
  pages = {728--742},
  publisher = {{American Psychological Association}},
  location = {{US}},
  abstract = {Comparing experts with novices offers unique insights into the functioning of cognition, based on the maximization of individual differences. Here we used this expertise approach to disentangle the mechanisms and neural basis behind two processes that contribute to everyday expertise: object and pattern recognition. We compared chess experts and novices performing chess-related and -unrelated (visual) search tasks. As expected, the superiority of experts was limited to the chess-specific task, as there were no differences in a control task that used the same chess stimuli but did not require chess-specific recognition. The analysis of eye movements showed that experts immediately and exclusively focused on the relevant aspects in the chess task, whereas novices also examined irrelevant aspects. With random chess positions, when pattern knowledge could not be used to guide perception, experts nevertheless maintained an advantage. Experts' superior domain-specific parafoveal vision, a consequence of their knowledge about individual domain-specific symbols, enabled improved object recognition. Functional magnetic resonance imaging corroborated this differentiation between object and pattern recognition and showed that chess-specific object recognition was accompanied by bilateral activation of the occipitotemporal junction, whereas chess-specific pattern recognition was related to bilateral activations in the middle part of the collateral sulci. Using the expertise approach together with carefully chosen controls and multiple dependent measures, we identified object and pattern recognition as two essential cognitive processes in expert visual cognition, which may also help to explain the mechanisms of everyday perception. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/georg/Zotero/storage/Q8TE2ARY/Bilalić et al. - 2010 - Mechanisms and neural basis of object and pattern .pdf},
  keywords = {Chess,Cognitions,Eye Movements,Functional Magnetic Resonance Imaging,Individual Differences,Insight,Object Recognition,Pattern Recognition (Cognitive Process)},
  number = {4}
}
% == BibLateX quality report for bilalic2010:
% Unexpected field 'publisher'
% Unexpected field 'location'

@manual{blender,
  title = {Blender - a {{3D}} Modelling and Rendering Package},
  author = {{Blender Online Community}},
  date = {2020},
  location = {{Stichting Blender Foundation, Amsterdam}},
  url = {http://www.blender.org},
  organization = {{Blender Foundation}},
  type = {manual}
}

@book{burkov2019,
  title = {The Hundred-Page Machine Learning Book},
  author = {Burkov, Andriy},
  date = {2019},
  publisher = {{Andriy Burkov}},
  location = {{Quebec, Canada}}
}

@article{canny1986,
  title = {A {{Computational Approach}} to {{Edge Detection}}},
  author = {Canny, J.},
  date = {1986-11},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {PAMI-8},
  pages = {679--698},
  abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  file = {/Users/georg/Zotero/storage/3ZQ54Z2Z/4767851.html},
  keywords = {Detectors,Edge detection,feature extraction,Feature extraction,Gaussian approximation,Image edge detection,image processing,machine vision,Machine vision,multiscale image analysis,Performance analysis,Shape measurement,Signal synthesis,Signal to noise ratio,Uncertainty},
  number = {6}
}
% == BibLateX quality report for canny1986:
% Unexpected field 'eventtitle'
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{chen2016,
  title = {Computer Vision Based Chess Playing Capabilities for the {{Baxter}} Humanoid Robot},
  booktitle = {International {{Conference}} on {{Control}}, {{Automation}} and {{Robotics}}},
  author = {Chen, Andrew Tzer-Yeu and Wang, Kevin I-Kai},
  date = {2016-04},
  pages = {11--14},
  abstract = {This paper presents a project that allows the Baxter humanoid robot to play chess against human players autonomously. The complete solution uses three main subsystems: computer vision based on a single camera embedded in Baxter's arm to perceive the game state, an open-source chess engine to compute the next move, and a mechatronics subsystem with a 7-DOF arm to manipulate the pieces. Baxter can play chess successfully in unconstrained environments by dynamically responding to changes in the environment. This implementation demonstrates Baxter's capabilities of vision-based adaptive control and small-scale manipulation, which can be applicable to numerous applications, while also contributing to the computer vision chess analysis literature.},
  eventtitle = {International {{Conference}} on {{Control}}, {{Automation}} and {{Robotics}}},
  file = {/Users/georg/Zotero/storage/NW2JUNT9/NW2JUNT9.pdf;/Users/georg/Zotero/storage/JQIYQEAN/7486689.html},
  keywords = {7-DOF arm,adaptive control,Baxter arm,Baxter humanoid robot,cameras,Cameras,chess robot,computer vision,Computer vision,computer vision based chess playing capabilities,dexterous manipulators,Engines,game state,grippers,human-robot interaction,humanoid robots,Image edge detection,mechatronics,Mechatronics,mechatronics subsystem,open-source chess engine,robot vision,Robot vision systems,single camera,small-scale manipulation,sport,two-finger gripper,unconstrained environments,uncontrolled environments,vision-based adaptive control}
}
% == BibLateX quality report for chen2016:
% ? Unsure about the formatting of the booktitle

@article{chen2019,
  title = {Robust {{Computer Vision Chess Analysis}} and {{Interaction}} with a {{Humanoid Robot}}},
  author = {Chen, Andrew Tzer-Yeu and Wang, Kevin I-Kai},
  date = {2019-03},
  journaltitle = {Computers},
  volume = {8},
  pages = {14},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  abstract = {As we move towards improving the skill of computers to play games like chess against humans, the ability to accurately perceive real-world game boards and game states remains a challenge in many cases, hindering the development of game-playing robots. In this paper, we present a computer vision algorithm developed as part of a chess robot project that detects the chess board, squares, and piece positions in relatively unconstrained environments. Dynamically responding to lighting changes in the environment, accounting for perspective distortion, and using accurate detection methodologies results in a simple but robust algorithm that succeeds 100\% of the time in standard environments, and 80\% of the time in extreme environments with external lighting. The key contributions of this paper are a dynamic approach to the Hough line transform, and a hybrid edge and morphology-based approach for object/occupancy detection, that enable the development of a robot chess player that relies solely on the camera for sensory input.},
  file = {/Users/georg/Zotero/storage/2IIDSADB/2IIDSADB.pdf;/Users/georg/Zotero/storage/JQV7VXXP/htm.html},
  issue = {1},
  keywords = {computer vision,human-robot interaction,image segmentation,mechatronics,morphological operations},
  langid = {english},
  number = {1}
}
% == BibLateX quality report for chen2019:
% Unexpected field 'publisher'
% ? Title looks like it was stored in title-case in Zotero

@report{cour2002,
  title = {Autonomous {{Chess}}-Playing {{Robot}}},
  author = {Cour, Timothée and Lauranson, Rémy and Vachette, Matthieu},
  date = {2002-07},
  institution = {{École Polytechnique}},
  location = {{Palaiseau, France}},
  url = {http://www.timotheecour.com/papers/ChessAutonomousRobot.pdf},
  file = {/Users/georg/Zotero/storage/HHJJC2BU/HHJJC2BU.pdf}
}
% == BibLateX quality report for cour2002:
% Missing required field 'type'

@inproceedings{czyzewski2018,
  title = {{{LATCHESS21}}: Dataset of Damaged Chessboard Lattice Points (Chessboard Features) Used to Train {{LAPS}} Detector (Grayscale/21x21px)},
  shorttitle = {{{LATCHESS21}}},
  author = {Czyzewski, Maciej A. and Laskowski, Artur and Wasik, Szymon},
  date = {2018},
  publisher = {{RepOD}},
  abstract = {LATCHESS21: dataset of damaged chessboard lattice points (chessboard features) used to train LAPS detector (grayscale/21x21px)}
}
% == BibLateX quality report for czyzewski2018:
% Missing required field 'booktitle'

@online{czyzewski2020,
  title = {Chessboard and Chess Piece Recognition with the Support of Neural Networks},
  author = {Czyzewski, Maciej A. and Laskowski, Artur and Wasik, Szymon},
  date = {2020-06-23},
  abstract = {Chessboard and chess piece recognition is a computer vision problem that has not yet been efficiently solved. However, its solution is crucial for many experienced players who wish to compete against AI bots, but also prefer to make decisions based on the analysis of a physical chessboard. It is also important for organizers of chess tournaments who wish to digitize play for online broadcasting or ordinary players who wish to share their gameplay with friends. Typically, such digitization tasks are performed by humans or with the aid of specialized chessboards and pieces. However, neither solution is easy or convenient. To solve this problem, we propose a novel algorithm for digitizing chessboard configurations. We designed a method that is resistant to lighting conditions and the angle at which images are captured, and works correctly with numerous chessboard styles. The proposed algorithm processes pictures iteratively. During each iteration, it executes three major sub-processes: detecting straight lines, finding lattice points, and positioning the chessboard. Finally, we identify all chess pieces and generate a description of the board utilizing standard notation. For each of these steps, we designed our own algorithm that surpasses existing solutions. We support our algorithms by utilizing machine learning techniques whenever possible. The described method performs extraordinarily well and achieves an accuracy over \$99.5\textbackslash\%\$ for detecting chessboard lattice points (compared to the \$74\textbackslash\%\$ for the best alternative), \$95\textbackslash\%\$ (compared to \$60\textbackslash\%\$ for the best alternative) for positioning the chessboard in an image, and almost \$95\textbackslash\%\$ for chess piece recognition.},
  archivePrefix = {arXiv},
  eprint = {1708.03898},
  eprinttype = {arxiv},
  file = {/Users/georg/Zotero/storage/AZA3P2FH/AZA3P2FH.pdf;/Users/georg/Zotero/storage/S6R2BDY3/1708.html},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}
% == BibLateX quality report for czyzewski2020:
% Unexpected field 'archivePrefix'

@online{danner2015,
  title = {Visual {{Chess Recognition}}},
  author = {Danner, Cheryl and Kafafy, Mai},
  date = {2015},
  url = {https://web.stanford.edu/class/ee368/Project_Spring_1415/Reports/Danner_Kafafy.pdf},
  abstract = {In this paper, we correctly detect and identify a chessboard and the configuration of its pieces through the application of image processing. While more technically challenging, the use of image processing to detect and identify a chessboard and the configuration of its pieces avoids the need for a digital chess set. Furthermore, image-based detection of chess pieces is a vital step in building chess-playing robots.},
  file = {/Users/georg/Zotero/storage/X8C2GS97/X8C2GS97.pdf},
  langid = {english}
}
% == BibLateX quality report for danner2015:
% ? Title looks like it was stored in title-case in Zotero

@article{delaescalera2010,
  title = {Automatic {{Chessboard Detection}} for {{Intrinsic}} and {{Extrinsic Camera Parameter Calibration}}},
  author = {De la Escalera, Arturo and Armingol, Jose María},
  date = {2010-03},
  journaltitle = {Sensors},
  volume = {10},
  pages = {2027--2044},
  publisher = {{Molecular Diversity Preservation International}},
  abstract = {There are increasing applications that require precise calibration of cameras to perform accurate measurements on objects located within images, and an automatic algorithm would reduce this time consuming calibration procedure. The method proposed in this article uses a pattern similar to that of a chess board, which is found automatically in each image, when no information regarding the number of rows or columns is supplied to aid its detection. This is carried out by means of a combined analysis of two Hough transforms, image corners and invariant properties of the perspective transformation. Comparative analysis with more commonly used algorithms demonstrate the viability of the algorithm proposed, as a valuable tool for camera calibration.},
  file = {/Users/georg/Zotero/storage/MHAN678P/De la Escalera and Armingol - 2010 - Automatic Chessboard Detection for Intrinsic and E.pdf},
  issue = {3},
  keywords = {camera calibration,chessboard detection,double Hough transform,pattern recognition},
  langid = {english},
  number = {3}
}
% == BibLateX quality report for delaescalera2010:
% Unexpected field 'publisher'
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{deng2009,
  title = {{{ImageNet}}: {{A}} Large-Scale Hierarchical Image Database},
  shorttitle = {{{ImageNet}}},
  booktitle = {{{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  date = {2009-06},
  pages = {248--255},
  abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
  eventtitle = {{{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  file = {/Users/georg/Zotero/storage/7RBGFYAI/Deng et al. - 2009 - ImageNet A large-scale hierarchical image databas.pdf;/Users/georg/Zotero/storage/K9JV3A9L/5206848.html},
  keywords = {computer vision,Explosions,Image databases,image resolution,image retrieval,Image retrieval,ImageNet database,Information retrieval,Internet,large-scale hierarchical image database,large-scale ontology,Large-scale systems,multimedia computing,multimedia data,Multimedia databases,Ontologies,ontologies (artificial intelligence),Robustness,Spine,subtree,trees (mathematics),very large databases,visual databases,wordNet structure}
}
% == BibLateX quality report for deng2009:
% ? Unsure about the formatting of the booktitle

@online{ding2016,
  title = {{{ChessVision}} : {{Chess Board}} and {{Piece Recognition}}},
  shorttitle = {{{ChessVision}}},
  author = {Ding, J.},
  date = {2016},
  url = {https://web.stanford.edu/class/cs231a/prev_projects_2016/CS_231A_Final_Report.pdf},
  abstract = {This paper details a method to take an image of a chess board and output a reconstructed computer representation of the board through board and piece recognition. Though techniques for board recognition have been thoroughly explored in the past, especially in relation to chessboard calibration, previous works on piece recognition often focus on non-robust segmentation procedures that rely heavily on the exact color of customized chess boards and pieces. The method presented in this paper improves upon the segmentation-based approaches of previous work in piece recognition by introducing a novel approach using classifiers trained on feature descriptors, which is more robust to the similarities in color seen in real-life chess boards. This work is important for both automating the recording of moves in human chess games and improving the ability of chess-playing AI that depend on vision.},
  file = {/Users/georg/Zotero/storage/Y7VJH2YW/Y7VJH2YW.pdf},
  langid = {english}
}
% == BibLateX quality report for ding2016:
% ? Title looks like it was stored in title-case in Zotero

@article{dottle2020,
  title = {The {{Chess Boom Goes Digital After}} ‘{{The Queen}}’s {{Gambit}}’},
  author = {Dottle, Rachael},
  date = {2020-12-16},
  journaltitle = {Bloomberg},
  abstract = {First came the pandemic. Then Netflix’s hit ‘The Queen’s Gambit.’ Americans are playing more chess},
  entrysubtype = {newspaper},
  file = {/Users/georg/Zotero/storage/W8V68XAM/2020-chess-boom.html},
  keywords = {bloomberg graphics,chess,data visualization,gaming,Netflix,retail,streaming,Twitch},
  langid = {english}
}
% == BibLateX quality report for dottle2020:
% ? Title looks like it was stored in title-case in Zotero

@article{duda1972,
  title = {Use of the {{Hough}} Transformation to Detect Lines and Curves in Pictures},
  author = {Duda, Richard O. and Hart, Peter E.},
  date = {1972-01-01},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {15},
  pages = {11--15},
  abstract = {Hough has proposed an interesting and computationally efficient procedure for detecting lines in pictures. This paper points out that the use of angle-radius rather than slope-intercept parameters simplifies the computation further. It also shows how the method can be used for more general curve fitting, and gives alternative interpretations that explain the source of its efficiency.},
  keywords = {colinear points,curve detection,Hough transformation,line detection,pattern recognition,picture processing,point-line transformation},
  number = {1}
}

@book{edwards1994,
  title = {{{PGN Standard}}},
  author = {Edwards, Steven J.},
  date = {1994-03-12},
  url = {http://archive.org/details/pgn-standard-1994-03-12},
  abstract = {Portable Game Notation Specification and Implementation Guide},
  keywords = {chess},
  langid = {english}
}
% == BibLateX quality report for edwards1994:
% ? Title looks like it was stored in title-case in Zotero

@online{elliott2019,
  title = {The State of the Octoverse},
  author = {Elliott, Thomas},
  date = {2019-01},
  publisher = {{GitHub Inc.}},
  url = {https://github.blog/2019-01-24-the-state-of-the-octoverse-machine-learning/},
  organization = {{The GitHub Blog}}
}
% == BibLateX quality report for elliott2019:
% Unexpected field 'publisher'

@inproceedings{ester1996,
  title = {A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise},
  booktitle = {International {{Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ester, Martin and Kriegel, Hans-Peter and Sander, Jörg and Xu, Xiaowei},
  date = {1996-08-02},
  location = {{Portland, Oregon}},
  abstract = {Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLAR-ANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.},
  keywords = {arbitrary shape of clusters,clustering algorithms,efficiency on large spatial databases,handling nlj4-275oise}
}
% == BibLateX quality report for ester1996:
% ? Unsure about the formatting of the booktitle

@article{fischler1981,
  title = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
  shorttitle = {Random Sample Consensus},
  author = {Fischler, Martin A. and Bolles, Robert C.},
  date = {1981-06-01},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {24},
  pages = {381--395},
  abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing},
  keywords = {automated cartography,camera calibration,image matching,location determination,model fitting,scene analysis},
  number = {6}
}

@online{friedlander2020,
  title = {From the ‘{{Queen}}’s {{Gambit}}’ to a {{Record}}-{{Setting Checkmate}}},
  author = {Friedlander, Peter},
  date = {2020-11-23},
  url = {https://about.netflix.com/en/news/the-queens-gambit-netflix-most-watched-scripted-limited-series},
  abstract = {The Queen’s Gambit now stands as our biggest scripted limited series ever. The series has captivated 62 million households in its first 28 days.},
  file = {/Users/georg/Zotero/storage/N9W6D2XW/the-queens-gambit-netflix-most-watched-scripted-limited-series.html},
  langid = {english},
  organization = {{About Netflix}}
}
% == BibLateX quality report for friedlander2020:
% ? Title looks like it was stored in title-case in Zotero

@article{fukushima1980,
  title = {Neocognitron: {{A}} Self-Organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position},
  shorttitle = {Neocognitron},
  author = {Fukushima, Kunihiko},
  date = {1980-04-01},
  journaltitle = {Biological Cybernetics},
  shortjournal = {Biol. Cybernetics},
  volume = {36},
  pages = {193--202},
  abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by “learning without a teacher”, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname “neocognitron”. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of “S-cells”, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of “C-cells” similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any “teacher” during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
  langid = {english},
  number = {4}
}

@inproceedings{glorot2011,
  title = {Deep {{Sparse Rectifier Neural Networks}}},
  booktitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  date = {2011-06-14},
  publisher = {{JMLR Workshop and Conference Proceedings}},
  abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neu...},
  eventtitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  file = {/Users/georg/Zotero/storage/8SWU5DER/Glorot et al. - 2011 - Deep Sparse Rectifier Neural Networks.pdf;/Users/georg/Zotero/storage/5AZ43Q7L/glorot11a.html},
  langid = {english}
}
% == BibLateX quality report for glorot2011:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{goncalves2005,
  title = {Chess Robot System : A Multi-Disciplinary Experience in Automation},
  shorttitle = {Chess Robot System},
  booktitle = {Spanish {{Portuguese Congress}} on {{Electrical Engineering}}},
  author = {Gonçalves, José and Lima, José and Leitão, Paulo},
  date = {2005},
  abstract = {This paper describes a chess robot system that allows remote users to play chess, using a six axes anthropomorphic robot to move chess pieces in the chessboard on getting commands from the player  and from the application chess engine. This experience allowed applying the concept of 'learning by doing', involving the integration of multi-disciplinary skills and teams.},
  annotation = {Accepted: 2010-02-12T17:20:43Z},
  eventtitle = {Spanish {{Portuguese Congress}} on {{Electrical Engineering}}},
  file = {/Users/georg/Zotero/storage/HVZYNFYL/HVZYNFYL.pdf},
  langid = {english}
}
% == BibLateX quality report for goncalves2005:
% ? Unsure about the formatting of the booktitle

@book{goodfellow2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  publisher = {{MIT Press}}
}

@report{hack2014,
  title = {{{CVChess}}: {{Computer Vision Chess Analytics}}},
  author = {Hack, Jay and Ramakrishnan, Prithvi},
  date = {2014},
  institution = {{Stanford University}},
  url = {https://web.stanford.edu/class/cs231a/prev_projects_2015/chess.pdf},
  abstract = {We present a computer vision application and a set of associated algorithms capable of recording chess game moves fully autonomously from the vantage point of a consumer laptop webcam. This consists of two main algorithms, (1) a hough transform-based algorithm for finding a homography relating board coordinates to image coordinates, and (2) a model of chessboard colors and occlusions that allows us to account for and infer piece movement in real time. We provide a video demonstration of the application applied to a real chess game and describe experiments in which our developed algorithms significantly outperform a naive baseline. All code is open sourced and available on GitHub.},
  file = {/Users/georg/Zotero/storage/SNSHYGUK/SNSHYGUK.pdf},
  langid = {english}
}
% == BibLateX quality report for hack2014:
% Missing required field 'type'
% ? Title looks like it was stored in title-case in Zotero

@article{halevy2009,
  title = {The Unreasonable Effectiveness of Data},
  author = {Halevy, Alon and Norvig, Peter and Pereira, Fernando},
  date = {2009},
  journaltitle = {IEEE Intelligent Systems},
  volume = {24},
  pages = {8--12}
}

@book{hartley2004,
  title = {Multiple {{View Geometry}} in {{Computer Vision}}},
  author = {Hartley, Richard and Zisserman, Andrew},
  date = {2004},
  edition = {2},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  abstract = {A basic problem in computer vision is to understand the structure of a real world scene given several images of it. Techniques for solving this problem are taken from projective geometry and photogrammetry. Here, the authors cover the geometric principles and their algebraic representation in terms of camera projection matrices, the fundamental matrix and the trifocal tensor. The theory and methods of computation of these entities are discussed with real examples, as is their use in the reconstruction of scenes from multiple images. The new edition features an extended introduction covering the key ideas in the book (which itself has been updated with additional examples and appendices) and significant new results which have appeared since the first edition. Comprehensive background material is provided, so readers familiar with linear algebra and basic numerical methods can understand the projective geometry and estimation algorithms presented, and implement the algorithms directly from the book.},
  file = {/Users/georg/Zotero/storage/FMAW7Q6I/0B6F289C78B2B23F596CAA76D3D43F7A.html}
}
% == BibLateX quality report for hartley2004:
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{he2016,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {{{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2016-06},
  pages = {770--778},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  eventtitle = {{{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  file = {/Users/georg/Zotero/storage/QZM7HGHS/He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf;/Users/georg/Zotero/storage/4ZEBADGE/7780459.html},
  keywords = {CIFAR-10,COCO object detection dataset,COCO segmentation,Complexity theory,deep residual learning,deep residual nets,deeper neural network training,Degradation,ILSVRC & COCO 2015 competitions,ILSVRC 2015 classification task,image classification,image recognition,Image recognition,Image segmentation,ImageNet dataset,ImageNet localization,ImageNet test set,learning (artificial intelligence),neural nets,Neural networks,object detection,residual function learning,residual nets,Training,VGG nets,visual recognition tasks,Visualization}
}
% == BibLateX quality report for he2016:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero

@online{he2019,
  title = {The {{State}} of {{Machine Learning Frameworks}} in 2019},
  author = {He, Horace},
  date = {2019-10-10},
  url = {https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/},
  abstract = {Since deep learning regained prominence in 2012, many machine learning frameworks have clamored to become the new favorite among researchers and industry practitioners. From the early academic outputs Caffe and Theano to the massive industry-backed PyTorch and TensorFlow, this deluge of options makes it difficult to keep track of what},
  file = {/Users/georg/Zotero/storage/N85Y6R8H/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry.html},
  organization = {{The Gradient}}
}
% == BibLateX quality report for he2019:
% ? Title looks like it was stored in title-case in Zotero

@report{hou,
  title = {Chessman {{Position Recognition Using Artificial Neural Networks}}},
  author = {Hou, Jun},
  abstract = {In the augmented reality chess game, a human user plays chess with a virtual user. To do realtime registration, the positions of the black chess pieces have to be found whenever the real world user makes a move. A Feed Forward Artificial Neural Network is used to recognize the chess piece positions. For training, images are acquired by synthesizing the chessboard and the pieces from different perspectives for different chess piece positions. To normalize the chessboard image with different perspectives, the chessboard corners are found and each chessboard square is divided into 8*8 smaller squares. Several variations of Gradient Descent algorithms in Back Propagation are examined. Although there is still much work to be done, the ANN approach has revealed its convenience and performance in this task. 1.},
  file = {/Users/georg/Zotero/storage/2GKJGMBC/Hou - Chessman Position Recognition Using Artificial Neu.pdf}
}
% == BibLateX quality report for hou:
% Exactly one of 'date' / 'year' must be present
% Missing required field 'type'
% Missing required field 'institution'
% ? Title looks like it was stored in title-case in Zotero

@patent{hough1962,
  title = {Method and Means for Recognizing Complex Patterns},
  author = {Hough, Paul V. C.},
  date = {1962-12-18},
  file = {/Users/georg/Zotero/storage/62VH83XE/Hough - 1962 - Method and means for recognizing complex patterns.pdf},
  holder = {{Paul V C Hough}},
  keywords = {framelet,line,microsecond,pulse,segment},
  number = {3069654A},
  type = {patentus}
}

@article{hubel1959,
  title = {Receptive Fields of Single Neurones in the Cat's Striate Cortex},
  author = {Hubel, D. H. and Wiesel, T. N.},
  date = {1959},
  journaltitle = {The Journal of Physiology},
  volume = {148},
  pages = {574--591},
  annotation = {\_eprint: https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.1959.sp006308},
  file = {/Users/georg/Zotero/storage/9VKX5XY2/Hubel and Wiesel - 1959 - Receptive fields of single neurones in the cat's s.pdf;/Users/georg/Zotero/storage/83UVEVYT/jphysiol.1959.html},
  number = {3}
}

@article{kanchibail2016,
  title = {Chess {{Board Recognition}}},
  author = {Kanchibail, Raghuveer and Suryaprakash, Supreeth and Jagadish, Suhas},
  date = {2016},
  url = {http://vision.soic.indiana.edu/b657/sp2016/projects/rkanchib/paper.pdf},
  abstract = {Chess Board recognition is an implementation which recognizes the chess board by locating the squares and detect the chess pieces from the input image using image processing techniques. The chess board is segmented from the input image, edges are detected using Canny’s edge detector and cross lines are detected using Hough transform. This will give us the required 64 squares. Each square, with some vicinity around it, is extracted and compared to see if it contains a chess piece. If yes, then the test piece is scaled and oriented to compare with the pre-defined training set. The area score is calculated by taking difference of training pieces and test piece and the one with the lowest score is chosen as the best matching piece.},
  file = {/Users/georg/Zotero/storage/NA9G2PZ9/NA9G2PZ9.pdf}
}
% == BibLateX quality report for kanchibail2016:
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@book{kasparov2018,
  title = {Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins},
  shorttitle = {Deep Thinking},
  author = {Kasparov, Garry and Greengard, Mig},
  date = {2018},
  annotation = {OCLC: 1083948333},
  isbn = {978-1-4736-5351-1},
  langid = {english}
}

@article{khan2014,
  title = {Design and Development of Autonomous Chess Playing Robot},
  author = {Khan, R Arif Mohamed and Kesavan, R},
  date = {2014},
  journaltitle = {International Journal of Innovative Science, Engineering \& Technology},
  volume = {1},
  file = {/Users/georg/Zotero/storage/KU32YVT4/KU32YVT4.pdf},
  number = {1}
}

@inproceedings{khater2012,
  title = {Chessboard Recognition System Using Signature, Principal Component Analysis and Color Information},
  booktitle = {International {{Conference}} on {{Digital Information Processing}} and {{Communications}}},
  author = {Khater, Ismail M. and Ghorab, Ahmed S. and Aljarrah, Inad A.},
  date = {2012-07},
  pages = {141--145},
  abstract = {This paper aims to implement a computer vision technique to translate an image into a description that can be read by computer programs to make decisions. The proposed system is applied to chessboard with a set of objects (pieces), and outputs the pieces names, locations, in addition to the pieces' colors. The signature feature has been used to distinguish the pieces types but when the signature comes to grief, the PCA (Principal Components Analysis) is used, and then the object color is obtained. The proposed system was trained and tested using Matlab, based on a set of collected samples using chessboard images. The simulation results show the effectiveness of the proposed method to recognize the pieces locations, types, and colors.},
  eventtitle = {International {{Conference}} on {{Digital Information Processing}} and {{Communications}}},
  file = {/Users/georg/Zotero/storage/6RHCCFAJ/6RHCCFAJ.pdf;/Users/georg/Zotero/storage/KR6VM9MY/6257285.html},
  keywords = {Chess,chessboard images,chessboard recognition system,color information,computer vision,Computer vision,Computer Vision,computer vision technique,Educational institutions,Euclidean distance,Euclidean Distance,feature extraction,Feature extraction,Image color analysis,image colour analysis,Matlab,Noise,object color,object recognition,PCA,piece color recognition,piece location recognition,piece type recognition,principal component analysis,Principal component analysis,signature feature,Signature Feature}
}
% == BibLateX quality report for khater2012:
% ? Unsure about the formatting of the booktitle

@online{kingma2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  date = {2017-01-29},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  archivePrefix = {arXiv},
  eprint = {1412.6980},
  eprinttype = {arxiv},
  file = {/Users/georg/Zotero/storage/LXDAPMDQ/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;/Users/georg/Zotero/storage/NMWGNYUY/1412.html},
  keywords = {Computer Science - Machine Learning}
}
% == BibLateX quality report for kingma2017:
% Unexpected field 'archivePrefix'
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{kornblith2019,
  title = {Similarity of Neural Network Representations Revisited},
  booktitle = {International {{Conference}} on {{Machine Learning}} ({{ICML}})},
  author = {Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  date = {2019-06},
  volume = {97},
  pages = {3519--3529},
  publisher = {{PMLR}},
  location = {{Long Beach, California, USA}},
  abstract = {Recent work has sought to understand the behavior of neural networks by comparing representations between layers and between different trained models. We examine methods for comparing neural network representations based on canonical correlation analysis (CCA). We show that CCA belongs to a family of statistics for measuring multivariate similarity, but that neither CCA nor any other statistic that is invariant to invertible linear transformation can measure meaningful similarities between representations of higher dimension than the number of data points. We introduce a similarity index that measures the relationship between representational similarity matrices and does not suffer from this limitation. This similarity index is equivalent to centered kernel alignment (CKA) and is also closely connected to CCA. Unlike CCA, CKA can reliably identify correspondences between representations in networks trained from different initializations.},
  pdf = {http://proceedings.mlr.press/v97/kornblith19a/kornblith19a.pdf}
}
% == BibLateX quality report for kornblith2019:
% Unexpected field 'pdf'
% ? Unsure about the formatting of the booktitle

@article{krizhevsky2017,
  title = {{{ImageNet}} Classification with Deep Convolutional Neural Networks},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  date = {2017-05-24},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {60},
  pages = {84--90},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  file = {/Users/georg/Zotero/storage/2IKLDZ6R/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf},
  number = {6}
}

@article{lecun1998,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {LeCun, Yann and Bottou, Léon and Bengio, Yoshua and Haffner, Patrick},
  date = {1998-11},
  journaltitle = {Proceedings of the IEEE},
  volume = {86},
  pages = {2278--2324},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
  file = {/Users/georg/Zotero/storage/NBTIQQL6/Lecun et al. - 1998 - Gradient-based learning applied to document recogn.pdf;/Users/georg/Zotero/storage/RPHYYN42/726791.html},
  keywords = {2D shape variability,back-propagation,backpropagation,Character recognition,cheque reading,complex decision surface synthesis,convolution,convolutional neural network character recognizers,document recognition,document recognition systems,Feature extraction,field extraction,gradient based learning technique,gradient-based learning,graph transformer networks,GTN,handwritten character recognition,handwritten digit recognition task,Hidden Markov models,high-dimensional patterns,language modeling,Machine learning,Multi-layer neural network,multilayer neural networks,multilayer perceptrons,multimodule systems,Neural networks,optical character recognition,Optical character recognition software,Optical computing,Pattern recognition,performance measure minimization,Principal component analysis,segmentation recognition},
  number = {11}
}

@article{lecun2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  date = {2015-05},
  journaltitle = {Nature},
  volume = {521},
  pages = {436--444},
  publisher = {{Nature Publishing Group}},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  file = {/Users/georg/Zotero/storage/RSND9FN8/nature14539.html},
  issue = {7553},
  langid = {english},
  number = {7553}
}
% == BibLateX quality report for lecun2015:
% Unexpected field 'publisher'

@inproceedings{matuszek2011,
  title = {Gambit: {{An}} Autonomous Chess-Playing Robotic System},
  shorttitle = {Gambit},
  booktitle = {{{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Matuszek, Cynthia and Mayton, Brian and Aimi, Roberto and Deisenroth, Marc Peter and Bo, Liefeng and Chu, Robert and Kung, Mike and LeGrand, Louis and Smith, Joshua R. and Fox, Dieter},
  date = {2011-05},
  pages = {4291--4297},
  abstract = {This paper presents Gambit, a custom, mid-cost 6-DoF robot manipulator system that can play physical board games against human opponents in non-idealized environments. Historically, unconstrained robotic manipulation in board games has often proven to be more challenging than the underlying game reasoning, making it an ideal testbed for small-scale manipulation. The Gambit system includes a low-cost Kinect-style visual sensor, a custom manipulator, and state-of-the-art learning algorithms for automatic detection and recognition of the board and objects on it. As a use-case, we describe playing chess quickly and accurately with arbitrary, uninstrumented boards and pieces, demonstrating that Gambit's engineering and design represent a new state-of-the-art in fast, robust tabletop manipulation.},
  eventtitle = {{{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  file = {/Users/georg/Zotero/storage/JGF8543C/JGF8543C.pdf;/Users/georg/Zotero/storage/24VZUPHE/5980528.html},
  keywords = {automatic board detection,automatic object detection,automatic object recognition,autonomous chess-playing robotic system,Cameras,Detectors,dexterous manipulators,Gambit robotic system,game reasoning,Games,Humans,Image color analysis,inference mechanisms,learning (artificial intelligence),low-cost Kinect-style visual sensor,manipulator kinematics,Mechanism Design of Manipulators,nonidealized environment,object detection,object recognition,physical board games,Physical Human Robot Interaction,Robot sensing systems,robot vision,robust tabletop manipulation,six-DoF robot manipulator system,small-scale manipulation,state-of-the-art learning algorithm,unconstrained robotic manipulation}
}
% == BibLateX quality report for matuszek2011:
% ? Unsure about the formatting of the booktitle

@article{mcculloch1943,
  title = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
  author = {McCulloch, Warren S. and Pitts, Walter},
  date = {1943-12-01},
  journaltitle = {Bulletin of Mathematical Biophysics},
  shortjournal = {Bulletin of Mathematical Biophysics},
  abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
  langid = {english}
}

@article{mehta2020,
  title = {Augmented {{Reality Chess Analyzer}} ({{ARChessAnalyzer}}): {{In}}-{{Device Inference}} of {{Physical Chess Game Positions}} through {{Board Segmentation}} and {{Piece Recognition}} Using {{Convolutional Neural Networks}}},
  shorttitle = {Augmented {{Reality Chess Analyzer}} ({{ARChessAnalyzer}})},
  author = {Mehta, Anav and Mehta, Huzefa},
  date = {2020-07-17},
  journaltitle = {Journal of Emerging Investigators},
  abstract = {Chess game position analysis is important in improving ones game. It requires entry of moves into a chess engine which is, cumbersome and error prone. We present ARChessAnalyzer, a complete pipeline from live image capture of a physical chess game, to board and piece recognition, to move analysis and finally to Augmented Reality (AR) overlay of the chess diagram position and move on the physical board. ARChessAnalyzer is like a scene analyzer - it uses an ensemble of traditional image and vision techniques to segment the scene (ie the chess game) and uses Convolution Neural Networks (CNNs) to predict the segmented pieces and combine it together to analyze the game. This paper advances the state of the art in the first of its kind end to end integration of robust detection and segmentation of the board, chess piece detection using the fine-tuned AlexNet CNN and chess engine analyzer in a handheld device app. The accuracy of the entire chess position prediction pipeline is 93.45\textbackslash\% and takes 3-4.5sec from live capture to AR overlay. We also validated our hypothesis that ARChessAnalyzer, is faster at analysis than manual entry for all board positions for valid outcomes. Our hope is that the instantaneous feedback this app provides will help chess learners worldwide at all levels improve their game.},
  file = {/Users/georg/Zotero/storage/3TMWTWFK/3TMWTWFK.pdf},
  keywords = {Computer Science - Human-Computer Interaction}
}

@inproceedings{neufeld2010,
  title = {Probabilistic Location of a Populated Chessboard Using Computer Vision},
  booktitle = {{{IEEE International Midwest Symposium}} on {{Circuits}} and {{Systems}}},
  author = {Neufeld, Jason E. and Hall, Tyson S.},
  date = {2010-08},
  pages = {616--619},
  abstract = {Development of autonomic chess-playing robots creates several interesting computer vision problems, including plane calibration and object recognition. Various solutions have been attempted, but most either require a modified chess set or place unreasonable constraints on board conditions and camera angles. A more general solution uses computer vision to automatically determine arbitrary chessboard location and identify chessmen on a standard, unmodified chess set. Although much work has been devoted to probabilistic image recognition in general, this paper presents a novel solution to the specific chessboard location problem that is accurate, less restrictive, and relatively time efficient.},
  eventtitle = {{{IEEE International Midwest Symposium}} on {{Circuits}} and {{Systems}}},
  file = {/Users/georg/Zotero/storage/YENCMSEI/YENCMSEI.pdf;/Users/georg/Zotero/storage/2J96EJBN/citations.html},
  keywords = {Calibration,Cameras,Chess,chess playing robots,computer vision,Computer vision,Educational institutions,Games,Humans,image recognition,Image recognition,intelligent robots,Machine vision,object recognition,Object recognition,plane calibration,populated chessboard,probabilistic location,robot vision,Robot vision systems,Robotics and automation}
}
% == BibLateX quality report for neufeld2010:
% ? Unsure about the formatting of the booktitle

@article{opencv2000,
  title = {The {{OpenCV}} Library},
  author = {Bradski, G.},
  date = {2000},
  journaltitle = {Dr. Dobb's Journal of Software Tools},
  citeulike-article-id = {2236121},
  keywords = {bibtex-import},
  posted-at = {2008-01-15 19:21:54},
  priority = {4}
}
% == BibLateX quality report for opencv2000:
% Unexpected field 'citeulike-article-id'
% Unexpected field 'posted-at'
% Unexpected field 'priority'
% ? Possibly abbreviated journal title Dr. Dobb's Journal of Software Tools

@incollection{pytorch2019,
  title = {{{PyTorch}}: {{An}} Imperative Style, High-Performance Deep Learning Library},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and family=Buc, given=F., prefix=dAlché-, useprefix=true and Fox, E. and Garnett, R.},
  date = {2019},
  pages = {8024--8035},
  publisher = {{Curran Associates, Inc.}}
}

@software{romstad2020,
  title = {Stockfish},
  author = {Romstad, Tord and Costalba, Marco and Kiiski, Joona},
  date = {2020-09-23T20:03:08Z},
  origdate = {2014-06-18T19:59:53Z},
  url = {https://github.com/official-stockfish/Stockfish},
  abstract = {UCI chess engine. Contribute to official-stockfish/Stockfish development by creating an account on GitHub.}
}
% == BibLateX quality report for romstad2020:
% Unexpected field 'title'
% Unexpected field 'author'

@software{roy2020,
  title = {Chessputzer},
  author = {Roy, Abhishek},
  date = {2020-07-12T17:29:53Z},
  origdate = {2017-11-16T13:25:09Z},
  url = {https://github.com/metterklume/chessputzer},
  abstract = {Image recognition for chess positions. Contribute to metterklume/chessputzer development by creating an account on GitHub.}
}
% == BibLateX quality report for roy2020:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@book{russell2010,
  title = {Artificial Intelligence: A Modern Approach},
  shorttitle = {Artificial Intelligence},
  author = {Russell, Stuart J. and Norvig, Peter and Davis, Ernest},
  date = {2010},
  edition = {3rd},
  publisher = {{Prentice Hall}},
  location = {{Upper Saddle River}},
  keywords = {Artificial intelligence}
}

@software{sameer2020,
  title = {Tensorflow\_chessbot},
  author = {Sameer, Ansari},
  date = {2020-09-06T06:59:21Z},
  origdate = {2016-02-08T09:52:24Z},
  url = {https://github.com/Elucidation/tensorflow_chessbot},
  abstract = {Predict chessboard FEN layouts from images using TensorFlow},
  keywords = {chess,chessboard,chessboard-detection,chessboard-recognition,tensorflow,tensorflow-examples,tensorflow-tutorials}
}
% == BibLateX quality report for sameer2020:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@inproceedings{simonyan2015,
  title = {Very {{Deep Convolutional Networks}} for {{Large}}-{{Scale Image Recognition}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Simonyan, Karen and Zisserman, Andrew},
  date = {2015-05},
  location = {{San Diego, USA}},
  eventtitle = {International {{Conference}} on {{Learning Representations}}}
}
% == BibLateX quality report for simonyan2015:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{sokic2008,
  title = {Simple {{Computer Vision System}} for {{Chess Playing Robot Manipulator}} as a {{Project}}-Based {{Learning Example}}},
  booktitle = {{{IEEE International Symposium}} on {{Signal Processing}} and {{Information Technology}}},
  author = {Sokic, Emir and Ahic-Djokic, Melita},
  date = {2008-12},
  pages = {75--79},
  abstract = {This paper presents an example of project-based learning (PBL) in an undergraduate course on Image processing. The design of a simple, low-cost computer vision system for implementation on a chess-playing capable robot is discussed. The system is based on a standard CCD camera and a personal computer. This project is a good tool for learning most of the course material that would otherwise be mastered by homework problems and study before an exam. An algorithm which detects chess moves is proposed. It compares two or more frames captured before, during and after a played chess move, and finds differences between them, which are used to define a played chess move. Further image processing is required to eliminate false readings, recognize direction of chess moves, end eliminate image distortion. Many Image processing problems and solutions can be introduced to students, through the proposed algorithm. The results are encouraging - students without any previous knowledge in image processing and advanced topics, such as artificial intelligence (neural networks etc.), may attain a chess move recognition success rate greater than 95\%, in controlled light environments.},
  eventtitle = {{{IEEE International Symposium}} on {{Signal Processing}} and {{Information Technology}}},
  file = {/Users/georg/Zotero/storage/AB75JXK3/AB75JXK3.pdf;/Users/georg/Zotero/storage/CZYM7VRA/4775676.html},
  keywords = {artificial intelligence,Cameras,CCD camera,Charge coupled devices,Charge-coupled image sensors,chess moves recognition,chess playing robot manipulator,computer vision,Computer vision,computer vision system,Educational robots,image distortion,image processing,Image processing,Image recognition,learning (artificial intelligence),manipulators,Manipulators,Process design,project-based learning,robot manipulator,Robot vision systems}
}
% == BibLateX quality report for sokic2008:
% ? Unsure about the formatting of the booktitle

@book{standage2003,
  title = {The {{Turk}}: The Life and Times of the Famous Eighteenth-Century Chess-Playing Machine},
  shorttitle = {The {{Turk}}},
  author = {Standage, Tom},
  date = {2003},
  publisher = {{Berkley Books}},
  location = {{New York}},
  annotation = {OCLC: 907018828},
  langid = {english}
}

@article{sung2008,
  title = {Pose {{Robust Face Tracking}} by {{Combining Active Appearance Models}} and~{{Cylinder~Head~Models}}},
  author = {Sung, Jaewon and Kanade, Takeo and Kim, Daijin},
  date = {2008-11-01},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {International Journal of Computer Vision},
  volume = {80},
  pages = {260--274},
  abstract = {The active appearance models (AAMs) provide the detailed descriptive parameters that are useful for various autonomous face analysis problems. However, they are not suitable for robust face tracking across large pose variation for the following reasons. First, they are suitable for tracking the local movements of facial features within a limited pose variation. Second, they use gradient-based optimization techniques for model fitting and the fitting performance is thus very sensitive to initial model parameters. Third, when their fitting is failed, it is difficult to obtain appropriate model parameters to re-initialize them. To alleviate these problems, we propose to combine the active appearance models and the cylinder head models (CHMs), where the global head motion parameters obtained from the CHMs are used as the cues of the AAM parameters for a good fitting or re-initialization. The good AAM parameters for robust face tracking are computed in the following manner. First, we estimate the global motion parameters by the CHM fitting algorithm. Second, we project the previously fitted 2D shape points onto the 3D cylinder surface inversely. Third, we transform the inversely projected shape points by the estimated global motion parameters. Fourth, we project the transformed 3D points onto the input image and computed the AAM parameters from them. Finally, we treat the computed AAM parameters as the initial parameters for the fitting. Experimental results showed that face tracking combining AAMs and CHMs is more pose robust than that of AAMs in terms of 170\% higher tracking rate and the 115\% wider pose coverage.},
  number = {2}
}
% == BibLateX quality report for sung2008:
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{szegedy2015,
  title = {Going Deeper with Convolutions},
  booktitle = {{{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  date = {2015-06},
  abstract = {We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
  eventtitle = {{{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  file = {/Users/georg/Zotero/storage/VRBHLFRH/Szegedy et al. - 2015 - Going deeper with convolutions.pdf;/Users/georg/Zotero/storage/NRDKBDLY/7298594.html},
  keywords = {architectural decision,Computer architecture,Computer vision,convolution,Convolutional codes,convolutional neural network architecture,decision making,feature extraction,Hebbian learning,Hebbian principle,image classification,neural net architecture,Neural networks,object classification,object detection,Object detection,resource allocation,resource utilization,Sparse matrices,Visualization}
}
% == BibLateX quality report for szegedy2015:
% ? Unsure about the formatting of the booktitle

@inproceedings{szegedy2016,
  title = {Rethinking the {{Inception Architecture}} for {{Computer Vision}}},
  booktitle = {{{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  date = {2016-06},
  pages = {2818--2826},
  abstract = {Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2\% top-1 and 5:6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5\% top-5 error and 17:3\% top-1 error on the validation set and 3:6\% top-5 error on the official test set.},
  eventtitle = {{{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  file = {/Users/georg/Zotero/storage/72E2E3VD/Szegedy et al. - 2016 - Rethinking the Inception Architecture for Computer.pdf;/Users/georg/Zotero/storage/QSNS76K4/7780677.html},
  keywords = {Benchmark testing,Computational efficiency,Computational modeling,Computer architecture,computer vision,Computer vision,Convolution,deep convolutional networks,ILSVRC 2012 classification challenge validation set,image classification,inception architecture,neural nets,Training}
}
% == BibLateX quality report for szegedy2016:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero

@incollection{szeliski2011,
  title = {Image Formation},
  booktitle = {Computer {{Vision}}: {{Algorithms}} and {{Applications}}},
  author = {Szeliski, Richard},
  date = {2011},
  pages = {27--86},
  publisher = {{Springer}},
  location = {{London}},
  abstract = {Before we can intelligently analyze and manipulate images, we need to establish a vocabulary for describing the geometry of a scene. We also need to understand the image formation process that produced a particular image given a set of lighting conditions, scene geometry, surface properties, and camera optics. In this chapter, we present a simplified model of such an image formation process},
  isbn = {978-1-84882-935-0},
  keywords = {Chromatic Aberration,Discrete Cosine Transform,Focal Length,Image Formation,Point Spread Function},
  langid = {english}
}
% == BibLateX quality report for szeliski2011:
% Missing required field 'editor'

@inproceedings{tam2008,
  title = {Automatic {{Grid Segmentation}} of {{Populated Chessboard Taken}} at a {{Lower Angle View}}},
  booktitle = {Digital {{Image Computing}}: {{Techniques}} and {{Applications}}},
  author = {Tam, K.Y. and Lay, J.A. and Levy, D.},
  date = {2008-12},
  pages = {294--299},
  abstract = {Segmentation of the chessboard grid is a crucial step in coordinate extraction for chess video annotation, content-based indexing of chess videos and for content analysis in prototyping vision systems such as a chess robot. This paper deals with the segmentation of grid elements from a populated chessboard taken at a lower angle view. The proposed approach couples the line-based grid detection method with domain knowledge of the chessboard to achieve improved accuracy and reliability.},
  eventtitle = {Digital {{Image Computing}}: {{Techniques}} and {{Applications}}},
  file = {/Users/georg/Zotero/storage/UKKUZ63K/UKKUZ63K.pdf;/Users/georg/Zotero/storage/MATIHE7Z/4700034.html},
  keywords = {automatic grid segmentation,chess,chess robot,chess video annotation,Computer applications,Computer vision,content-based indexing,Design engineering,Detectors,Digital images,edge detection,Games,Grid computing,grid detection,image segmentation,Image segmentation,Indexing,line-based grid detection method,lower angle view,populated chessboard,Video equipment,vision system}
}
% == BibLateX quality report for tam2008:
% ? Title looks like it was stored in title-case in Zotero

@article{tensorflow2015whitepaper,
  title = {{{TensorFlow}}: {{Large}}-Scale Machine Learning on Heterogeneous Systems},
  author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mané, Dandelion and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viégas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  date = {2015}
}
% == BibLateX quality report for tensorflow2015whitepaper:
% Missing required field 'journaltitle'

@inproceedings{urting2003,
  title = {{{MarineBlue}}: {{A}} Low-Cost Chess Robot},
  booktitle = {International Conference Robotics and Applications},
  author = {Urting, David and Berbers, Yolande},
  date = {2003-06},
  pages = {76--81},
  location = {{Salzburg, Austria}},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/ra/UrtingB03.bib},
  eventtitle = {International Conference Robotics and Applications},
  file = {/Users/georg/Zotero/storage/76VZEI2M/76VZEI2M.pdf},
  timestamp = {Thu, 30 Oct 2003 07:57:45 +0100}
}
% == BibLateX quality report for urting2003:
% Unexpected field 'bibsource'
% Unexpected field 'biburl'
% Unexpected field 'timestamp' (added because JabRef format is set to ?)
% ? Unsure about the formatting of the booktitle

@inproceedings{wang2013,
  title = {Chess Move Tracking Using Overhead {{RGB}} Webcam},
  booktitle = {International {{Conference}} on {{Image}} and {{Vision Computing New Zealand}}},
  author = {Wang, Victor and Green, Richard},
  date = {2013-11},
  pages = {299--304},
  abstract = {This paper proposes a real-time application for detecting the moves of a chess game given a video stream from a camera positioned over the board. A custom implementation based on square identification of flood filled regions is used to detect colored chessboards in arbitrary backgrounds. The detected board is transformed to a normalized image, and occupancy of the chessboard is determined by classifying the pixels within each square of the 8×8 grid to check for a piece of a given color. A move is recognized when the current occupancy grid matches the chessboard that results from one of the possible moves from the previous occupancy grid. These moves and occupancy grids are supplied by a chess engine. A simple motion detection method is used to avoid processing frames in which a player is obscuring any part of the board. It uses hysteretic n-frame thresholding of difference images.},
  eventtitle = {International {{Conference}} on {{Image}} and {{Vision Computing New Zealand}}},
  file = {/Users/georg/Zotero/storage/XZKJQBGL/XZKJQBGL.pdf;/Users/georg/Zotero/storage/8P2VWIG4/6727033.html},
  keywords = {camera,Cameras,chess game,chess move tracking,chessboard color detection,computer games,flood fill square detection,Floods,Games,grid matches,Image color analysis,image sensors,Lighting,motion detection method,motion estimation,n-frame hysteretic motion filter,object tracking,overhead RGB Webcam,real-time application,real-time chess move detection,Robots,Robustness,square identification,video stream,video streaming}
}
% == BibLateX quality report for wang2013:
% ? Unsure about the formatting of the booktitle

@inproceedings{wei2017,
  title = {Chess Recognition from a Single Depth Image},
  booktitle = {{{IEEE International Conference}} on {{Multimedia}} and {{Expo}}},
  author = {Wei, Yu-An and Huang, Tzu-Wei and Chen, Hwann-Tzong and Liu, JenChi},
  date = {2017-07},
  pages = {931--936},
  abstract = {This paper presents a learning-based method for recognizing chess pieces from depth information. The proposed method is integrated in a recreational robotic system that is designed to play games of chess against humans. The robot has two arms and an Ensenso N35 Stereo 3D camera. Our goal is to provide the robot visual intelligence so that it can identify the chess pieces on the chessboard using the depth information captured by the 3D camera. We build a convolutional neural network to solve this 3D object recognition problem. While training neural networks for 3D object recognition becomes popular these days, collecting enough training data is still a time-consuming task. We demonstrate that it is much more convenient and effective to generate the required training data from 3D CAD models. The neural network trained using the rendered data performs well on real inputs during testing. More specifically, the experimental results show that using the training data rendered from the CAD models under various conditions enhances the recognition accuracy significantly. When further evaluations are done on real data captured by the 3D camera, our method achieves 90.3\% accuracy.},
  eventtitle = {{{IEEE International Conference}} on {{Multimedia}} and {{Expo}}},
  file = {/Users/georg/Zotero/storage/KUJJZ7KS/KUJJZ7KS.pdf;/Users/georg/Zotero/storage/KN8VKTTK/8019453.html},
  keywords = {3D CAD models,3D object recognition,3D object recognition problem,CAD,Cameras,chess pieces,chess recognition,convolutional neural network,convolutional neural networks,depth information,Ensenso N35 Stereo 3D camera,feedforward neural nets,learning (artificial intelligence),learning-based method,object recognition,Object recognition,recreational robotic system,robot vision,robot visual intelligence,Robots,single depth image,Solid modeling,solid modelling,stereo image processing,Three-dimensional displays,Training data,volumetric representation}
}
% == BibLateX quality report for wei2017:
% ? Unsure about the formatting of the booktitle

@online{wu2020,
  title = {Visual {{Transformers}}: {{Token}}-Based {{Image Representation}} and {{Processing}} for {{Computer Vision}}},
  shorttitle = {Visual {{Transformers}}},
  author = {Wu, Bichen and Xu, Chenfeng and Dai, Xiaoliang and Wan, Alvin and Zhang, Peizhao and Yan, Zhicheng and Tomizuka, Masayoshi and Gonzalez, Joseph and Keutzer, Kurt and Vajda, Peter},
  date = {2020-11-19},
  abstract = {Computer vision has achieved remarkable success by (a) representing images as uniformly-arranged pixel arrays and (b) convolving highly-localized features. However, convolutions treat all image pixels equally regardless of importance; explicitly model all concepts across all images, regardless of content; and struggle to relate spatially-distant concepts. In this work, we challenge this paradigm by (a) representing images as semantic visual tokens and (b) running transformers to densely model token relationships. Critically, our Visual Transformer operates in a semantic token space, judiciously attending to different image parts based on context. This is in sharp contrast to pixel-space transformers that require orders-of-magnitude more compute. Using an advanced training recipe, our VTs significantly outperform their convolutional counterparts, raising ResNet accuracy on ImageNet top-1 by 4.6 to 7 points while using fewer FLOPs and parameters. For semantic segmentation on LIP and COCO-stuff, VT-based feature pyramid networks (FPN) achieve 0.35 points higher mIoU while reducing the FPN module's FLOPs by 6.5x.},
  archivePrefix = {arXiv},
  eprint = {2006.03677},
  eprinttype = {arxiv},
  file = {/Users/georg/Zotero/storage/QJ34LEXN/Wu et al. - 2020 - Visual Transformers Token-based Image Representat.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing}
}
% == BibLateX quality report for wu2020:
% Unexpected field 'archivePrefix'

@inproceedings{xie2018,
  title = {Chess {{Piece Recognition Using Oriented Chamfer Matching}} with a {{Comparison}} to {{CNN}}},
  booktitle = {{{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  author = {Xie, Youye and Tang, Gongguo and Hoff, William},
  date = {2018-03},
  pages = {2001--2009},
  abstract = {Recognizing three dimensional chess pieces using computer vision is needed for an augmented reality chess assistant. This paper proposes an efficient 3D pieces recognition approach based on oriented chamfer matching. During a real game, the pieces might be occluded by other pieces and have varying rotation and scales with respect to the camera. Furthermore, different pieces share lots of similar texture features which makes them more difficult to identify. Our approach addresses the above problems and is capable of identifying the pieces with different scales, rotation and viewing angles. After marking the possible chessboard squares that contain pieces, the oriented chamfer scores are calculated for alternative templates and the recognized pieces are indicated on the input image accordingly. Our approach shows high recognition accuracy and efficiency in experiments and the recognition process can be easily generalized to other pattern recognition applications with 3D templates. Our approach outperforms the convolutional neural networks under severe occlusion and low resolution conditions and has comparative processing time while avoids the time consuming training process.},
  eventtitle = {{{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  file = {/Users/georg/Zotero/storage/78AK3KIJ/78AK3KIJ.pdf;/Users/georg/Zotero/storage/4LZXSLEJ/8354325.html},
  keywords = {3D pieces recognition approach,augmented reality,augmented reality chess assistant,Cameras,chessboard squares,computer vision,convolutional neural networks,feature extraction,Feature extraction,feedforward neural nets,Games,high recognition accuracy,Image color analysis,Image edge detection,image matching,image texture,object detection,oriented chamfer matching,oriented chamfer scores,texture features,three dimensional chess piece recognition,Three-dimensional displays}
}
% == BibLateX quality report for xie2018:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{xie2018a,
  title = {Geometry-Based Populated Chessboard Recognition},
  booktitle = {International {{Conference}} on {{Machine Vision}}},
  author = {Xie, Youye and Tang, Gongguo and Hoff, William},
  date = {2018-04-13},
  volume = {10696},
  pages = {1069603},
  publisher = {{International Society for Optics and Photonics}},
  abstract = {Chessboards are commonly used to calibrate cameras, and many robust methods have been developed to recognize the unoccupied boards. However, when the chessboard is populated with chess pieces, such as during an actual game, the problem of recognizing the board is much harder. Challenges include occlusion caused by the chess pieces, the presence of outlier lines and low viewing angles of the chessboard. In this paper, we present a novel approach to address the above challenges and recognize the chessboard. The Canny edge detector and Hough transform are used to capture all possible lines in the scene. The k-means clustering and a k-nearest-neighbors inspired algorithm are applied to cluster and reject the outlier lines based on their Euclidean distances to the nearest neighbors in a scaled Hough transform space. Finally, based on prior knowledge of the chessboard structure, a geometric constraint is used to find the correspondences between image lines and the lines on the chessboard through the homography transformation. The proposed algorithm works for a wide range of the operating angles and achieves high accuracy in experiments.},
  eventtitle = {International {{Conference}} on {{Machine Vision}}},
  file = {/Users/georg/Zotero/storage/2A5PFNWV/2A5PFNWV.pdf}
}
% == BibLateX quality report for xie2018a:
% ? Unsure about the formatting of the booktitle

@online{young2020,
  title = {The {{Queen}}’s {{Gambit}} Sparks Surge in Searches for Chess Sets},
  author = {Young, Sarah},
  date = {2020-11-11},
  abstract = {Fans of the show are spending the second lockdown inflicting checkmates of their own},
  file = {/Users/georg/Zotero/storage/V9BF4N8Y/chess-set-sales-queens-gambit-netflix-ebay-b1720972.html},
  organization = {{The Independent}}
}
% == BibLateX quality report for young2020:
% At least one of 'url' / 'doi' / 'eprint' must be present

@online{zhou2018,
  title = {Pattern Recognition in Chess},
  author = {Zhou, Qiyu},
  date = {2018-05-30},
  url = {https://en.chessbase.com/post/pattern-recognition-in-chess},
  abstract = {Is there a correlation between the strength in chess of players and their ability to recall a position in chess using short-term memory? This was the research question of a budding young scientist, QIYU ZHOU, who gave professional and casual chess players positions to study and then attempt to reconstruct them within 30 seconds. Her results are meticulously documented in a paper we are pleased to publish. At the end, there is an appeal to our readers to help with associated material.},
  langid = {english},
  organization = {{ChessBase}}
}


