\section{Context survey}
This context survey will examine not only past approaches to chess recognition, but also current implementation tools that will be useful for designing such a system.

\subsection{Chess recognition}
Determining the game state of a chess board, also known as \emph{chess recognition}, is a problem in computer vision whereby an algorithm is tasked with recovering the configuration of pieces from an image of a chessboard.
Early work on chess recognition in the 1990s focused on extracting typeset games from printed material \cite{baird1990}. 
In recent years, the problem of parsing two-dimensional chess images has effectively been solved using conventional machine learning techniques \cite{khater2012} and deep learning \cite{sameer2020,roy2020}.
However, recognising chess positions from physical chessboards as opposed to artificial two-dimensional images poses a much more interesting and challenging problem that finds practial application in chess-playing robots, augmented reality, and aiding amateur chess players\footnote{Electronic chess sets are impractical and very costly \cite{wang2013}, thus solutions for chess recognition using just a photo of an unmodified chess board are more compelling for amateur chess players.}.

\paragraph{Chess robots}
Initial research into chess recognition emerged from the development of chess robots that included a camera to detect the human opponent's moves from a top-down overhead perspective. 
The difficulty of distinguishing between chess pieces from a bird's-eye-view due to their similarity is noted in many papers; as a result, chess robots typically implement a three-way classification system that for every square attempts to determine whether it contains a piece, and, if so, that piece's colour.
Various approaches have been explored including
  employing manual thresholding \cite{cour2002,urting2003,banerjee2012,chen2016} and clustering \cite{goncalves2005} in different colour spaces, as well as
  differential imaging (classifying based on the per-pixel difference between two images) \cite{khan2014,chen2019}.
Although the \emph{Gambit} robot proposed by \textcite{matuszek2011} does not require a bird's-eye view over the chessboard and uses a depth camera to more reliably detect the occupancy of each square, it employs the three-way classification strategy using a linear \gls{svm} to determine the piece colour. 

\paragraph{Chess move recording}
Several techniques for recording chess moves from video footage have been proposed that follow a similar three-way occupancy and colour classification scheme, both from a top-down perspective \cite{sokic2008,wang2013} as well as from a camera positioned at an acute angle to the board \cite{hack2014}.
However, in any such three-way classification approach, the robot or move recorder requires knowledge of the previous board state in addition to its predictions for each square's occupancy and piece colour to deduce the last move. 
While this information is readily available to a chess robot or move recording software, it is not for a chess recognition system that should deduce the position from a single still image.
Furthermore, these approaches experience severe shortcomings in terms of their inability to recover once a single move was predicted incorrectly and fail to identify promoted pieces\footnote{Piece promotion occurs when a pawn reaches the last rank, in which case the player must choose to promote to a queen, rook, bishop or knight. Evidently, a vision system that can only detect the piece's colour is unable to detect what it was promoted to.} \cite{cour2002}.

\paragraph{Single-image chess recognition}
A number of techniques have been developed to address the issue of chess recognition from a single image. 
Unlike move recording software or chess robots, the squares' occupancy and colour alone provide insufficient information to determine the position. 
These techniques must instead implement a classification algorithm for each piece type (pawn, knight, bishop, queen, and king) of each colour which poses a significantly more difficult problem, attracting research mainly in the last five years.
From a bird's-eye view, the pieces are nearly indestinguishable, hence the photo is usually taken at an acute angle to the board.
\textcite{ding2016} proposes a piece classifier that uses one-versus-rest \glspl{svm} trained on \gls{sift} and \gls{hog} feature descriptors, achieving an accuracy of 85\%. 
Conversely, \textcite{danner2015} as well as \textcite{xie2018} claim that \gls{sift} and \gls{hog} provide inadequate features for the problem of piece classification due to the similarity in texture between chess pieces, and instead focus on the pieces' outlines.
As such, \textcite{danner2015} use Fourier descriptors calculated based on the pieces' contours, but this requires a manually-created database of piece silhouettes.
Furthermore, they modify the board colours to red and green instead of black and white, in order distinguish the pieces from the board more easily\footnote{Similar board modifications have also been proposed as part of chess robots \cite{banerjee2012} and chess move trackers \cite{wang2013}, but any such modification imposes an unreasonable constraint on normal chess games.}.
On the other hand, \textcite{xie2018} perform contour-based template matching with an interesting caveat: the camera angle is calculated based on the perspective transformation of the chessboard, and then depending on the angle, different templates are utilised for matching the chess pieces.
As part of the same work, \citeauthor{xie2018} develop another approach that instead utilises \glspl{cnn}, but find that their original template-matching technique achieves superior results in terms of speed and accuracy in low-resolution images.
However, the reader should note that their \glspl{cnn} are trained on only 40 images per class and deep learning methods tend to excel when trained on larger datasets.

\paragraph{Chessboard detection}
A prerequisite to any chess recognition system is the ability to detect the location of the chessboard and each of the 64 squares. 
Once the four corner points have been established, finding the squares is trivial for pictures captured in bird's-eye view, and only a matter of a simple perspective transformation in the case of other camera positions.
While finding the corner points of a chessboard is frequently used for automatic camera calibration due to the regular nature of the chessboard pattern \cite{delaescalera2010,bennett2014}, techniques designed for this purpose tend to perform poorly when there are pieces on the chessboard that occlude lines or corners.
Some of the aforementioned chess robots \cite{goncalves2005,sokic2008,khan2014} as well as the single-image recognition system proposed by \textcite{danner2015} circumvent this problem entirely by prompting the user to interactively select the four corner points, but ideally a chess recognition system should be able to parse the position on the board without human intervention.
Most approaches for automatic chess grid detection utilise either the Harris corner detector \cite{banerjee2012,hack2014} or a form of line detector based on the Hough transform \cite{tam2008,neufeld2010,danner2015,chen2016,kanchibail2016,xie2018a,chen2019}, although other techniques such as template matching \cite{matuszek2011} and flood fill \cite{wang2013} have been explored.
In general, corner-based algorithms are unable to accurately detect grid corners when they are occluded by pieces, thus line-based detection algorithms appear to be the favoured solution.
Such algorithms often take advantage of the geometric nature of the chessboard which allows to compute a perspective transformation of the grid lines that best matches the detected lines \cite{tam2008,hack2014,xie2018}.
However, lines found in the background of the photo can often cause failure modes.
A recent chess grid detection algorithm that is highly successful even on populated boards is descibed by \citeauthor{xie2018a} in \cite{xie2018a}. 
They apply several clustering algorithms on the lines detected via a Hough transform in order to find the horizontal and vertical grid lines belonging to the chessboard, and use this algorithm as a preprocessing step in their template-matching piece classification technique \cite{xie2018} described above. 

\paragraph{Chess recognition using \glspl{cnn}}
Ever since \citeauthor{xie2018} pioneered the use of \glspl{cnn} in the domain of chess recognition from monocular images in \citeyear{xie2018}%
\footnote{%
    \textcite{wei2017} developed a chess recognition system using a volumetric CNN one year previously, but this approach requires three-dimensional chessboard data obtained from a depth camera. 
    Their approach achieved a per-class accuracy over 90\% except for the ``king'' class, was trained on \gls{cad} models, and evaluated on real three-dimensional images (point clouds) of a chessboard.
},
a few more techniques have been developed that employ \glspl{cnn} at various stages in the recognition pipeline.
\textcite{czyzewski2020} achieve an accuracy of 95\% on chessboard detection from non-vertical camera angles by designing an iterative algorithm that gereates heatmaps over the input image representing the likelihood of each pixel being part of the chessboard. 
They then employ a \gls{cnn} to refine the corner points that were found using the heatmap, outperforming the results obtained by \textcite{goncalves2005}.
Furthermore, they compare a \gls{cnn}-based piece classification algorithm to the SVM-based solution proposed by \textcite{ding2016} and find no notable amelioration, but manage to obtain major improvements by implementing a probabilistic reasoning system that uses the open source Stockfish chess engineÂ \cite{romstad2020} as well as chess statistics \cite{acher2016}.
Although reasoning techniques were already employed for refining the predictions of chess recognition systems before \cite{neufeld2010,danner2015}, \citeauthor{czyzewski2020} demonstrate the potential of combining information obtained from a chess engine with large-scale chess statistics.  
Very recently, \textcite{mehta2020} implemented an augmented reality app using the popular \emph{AlexNet} \gls{cnn} architecture introduced by \textcite{krizhevsky2017}, achieving promising results.
Despite using an overhead camera perspective and not performing any techniques to ensure probable and legal chess positions, \citeauthor{mehta2020} achieve an end-to-end accuracy of 93\% for the entire chessboard detection and piece classification pipeline, which -- to the best of our knowledge -- constitutes the current state of the art.
However, it is unclear whether this accuracy is reported on the training set or a possible held-out test set.

\paragraph{Datasets}
The lack of adequate datasets for chess recognition has been recognised by many \cite{czyzewski2020,ding2016,mehta2020}.
Although \textcite{czyzewski2020} published a dataset of chessboard lattice points that are difficult to predict \cite{czyzewski2018}, large datasets -- especially at the scale required for deep learning -- are not available as of now.
Using synthesised data in the training set is an efficient means of creating sizable datasets while minimising the manual annotation efforts \cite{wei2017,hou,czyzewski2020}.
\citeauthor{czyzewski2020} distort some input images in order to simulate different camera perspectives on the chessboard corners.
However, a more promising method seems to be the use of three-dimensional models.
\textcite{wei2017} synthesise point cloud data for their volumetric \gls{cnn} directly from three-dimensional chess models and \textcite{hou} use renderings of three-dimensional models as input. 
Yet \textcite{wei2017}'s approach works only if the chessboard was captured with a depth camera and \textcite{hou} presents a chessboard recognition system using a simple \gls{ann} that is not convolutional and hence achieves an accuracy of only 72\%.

\subsection{Implementation tools}
% This project will adopt Python as the main programming language.
In both acedemia and industry, Python is the de facto standard programming language for machine learning. 
A 2019 analysis conducted on the world-leading software development platform \href{https://www.github.com/}{GitHub} found that Python is the most popular language for open source machine learning repositories \cite{elliott2019}.
Python is a simple yet versatile language that natively supports different programming paradigms (imperative, functional, object-oriented, and more).
It is often called an interpreted language\footnote{There is nuance associated with this statement, but Python certainly exhibits more traits of an interpreted than a compiled language.} because it is dynamically typed and performs automatic memory management (garbage collection) which generally facilitates shorter code than compiled languages such as C or Java, but also means that pure-Python implementations of data-intensive algorithms will usually not be as efficient.
One of the most fundamental packages, \href{https://numpy.org/}{NumPy}, implements very efficient array manipulation operations that, although specified in Python, are carried out at a lower level for performance.

NumPy is just one piece of Python's rich ecosystem of packages that are maintained by open-source contributers in the scientific and engineering community.
The two main frameworks for machine learning are \href{https://www.tensorflow.org/}{TensorFlow} by Google and \href{https://www.pytorch.org/}{PyTorch} by Facebook. 
At their core, both frameworks facilitate the computation of mathematical operations on tensors\footnote{Tensors are essentially a generalisation of scalars, vectors, and matrices. They can be thought of as representing a multi-dimensional array.}, offering support for hardware acceleration via \glspl{gpu} and providing parallelisation strategies for distributed computing which is especially potent in the context of machine learning where many operations fit the \textit{single instruction, multple data} (SIMD) pattern.
A TensorFlow program is specified as a directed \textit{computational graph} where nodes represent operations and edges represent their inputs and outputs (data tensors) \cite{tensorflow2015whitepaper}.
In the new TensorFlow 2, this graph does not need to be explicitly constructed in the code anymore but is created on the fly which is known as \textit{eager execution}, thereby providing the user with a simpler interface similar to NumPy.
The slightly younger PyTorch framework provided dynamic computation graphs and a NumPy-like interface from the outset at its initial release in 2016, and more recently added support for static computational graphs.
Hence the newest versions of both frameworks provide similar programming interfaces and computational capabilities.
They also facilitate the automatic computation of gradients which is useful for training neural networks. 
In the research community, PyTorch recently overtook TensorFlow in terms of popularity; at every top machine learning conference since 2019, the majority of submissions with code were implemented in PyTorch \cite{he2019}.

One should not overlook the concept of interactive notebooks made possible by Python's interpreted nature -- that is, mixing rich text (markdown), Python code, and its output. 
Not only does this allow the programmer to make changes to the code without having to rerun the program, but it also provides a means of presenting Python code in a more engaging way than just comments.
Any type of Python output, including data visualisations, can be presented in such notebooks which makes it attractive for machine learning.
These notebooks can be created using the \href{https://jupyter.org/}{Jupyter} package or even run online with services such as \href{https://colab.research.google.com/}{Google Colab}. 